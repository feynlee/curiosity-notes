[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Trained as a theoretical particle physicist | Now a data scientist and AI practitioner\n\nA curious mind, ignorant and eager to learn\nSharing what I learn about science, AI, coding and life in general\nLooking for like-minded people to connect"
  },
  {
    "objectID": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html",
    "href": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html",
    "title": "How to Release Your First iOS App",
    "section": "",
    "text": "I just released my first iOS app, and man did I underestimate the App Submission process! I wish there was a handy compilation of resources and tips from someone that just went through this. That could’ve saved me loads of time!\nSo I’m sharing my learnings here for people like me.\nThis video provides great instructions on how to submit your app to the App Store. I won’t repeat what has already been mentioned in the video. Instead, I will focus on the issues I encountered during the submission process that are not covered in the video."
  },
  {
    "objectID": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#you-can-bypass-setting-up-export-compliance-in-app-store-connect",
    "href": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#you-can-bypass-setting-up-export-compliance-in-app-store-connect",
    "title": "How to Release Your First iOS App",
    "section": "You Can Bypass Setting Up Export Compliance in App Store Connect",
    "text": "You Can Bypass Setting Up Export Compliance in App Store Connect\nAfter archiving your app and uploading it to App Store Connect, you will be prompted to set up export compliance. Refer to the screenshot below to see the “missing compliance” status for BUILD 2.\n \nYou can actually bypass the process of setting up export compliance in App Store Connect by specifying your use of encryption directly in the information property list (Info.plist) of your Xcode project.\nTo do this, add the App Uses Non-Exempt Encryption key to your Info.plist file and set its value to NO."
  },
  {
    "objectID": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#testflight",
    "href": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#testflight",
    "title": "How to Release Your First iOS App",
    "section": "TestFlight",
    "text": "TestFlight\nMake use of TestFlight to ensure that your app functions properly before submission!\nYou can set up a beta testing group and add yourself as a tester.\n\n\n\ntestflight\n\n\nNext, download the TestFlight app from the App Store and install your app for testing purposes. During testing, you will not be charged for in-app purchases when you click on the purchase button.\nI neglected to use TestFlight for beta testing my app, and as a result, I had to wait for two days for my app to be rejected due to missing in-app purchases, as explained in the next section. Subsequently, it took an additional day for my app to be approved after resolving these issues."
  },
  {
    "objectID": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#in-app-purchase",
    "href": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#in-app-purchase",
    "title": "How to Release Your First iOS App",
    "section": "In-App Purchase",
    "text": "In-App Purchase\n\nHow to Set Up In-App Purchase in Your Code\n\nYou can obtain the author’s demo code from GitHub. With minimal modifications, you can utilize the demo code to implement in-app purchases in your app.\n\n\nSetting Up In-App Purchase on App Store Connect\n\nProduct IDs\nWhile I was following the video without fully comprehending how product IDs are used, I encountered some issues when submitting my app on App Store Connect.\nHere’s the crucial part that I overlooked:\n\n\n\n\n\n\nImportant\n\n\n\nThe Product IDs you set up on App Store Connect must match those you used during local testing, specifically the ones you configured with the Product.storekit file.\n\n\n\n\nFailing to do so will result in your app being unable to find the expected products, and the in-app purchase will not appear correctly. This is where beta testing with TestFlight would have been beneficial in identifying this issue.\nPaid Agreement\nThere are a few other configurations required for In-App Purchase. One of them is to accept the paid agreement. You can find the paid agreement in the “Agreements, Tax, and Banking” section of App Store Connect.\n\n\n\npaid_agreement\n\n\nYou will need to set up a bank account for accepting payments, which leads us to the next section: sole proprietorship."
  },
  {
    "objectID": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#sole-proprietorship",
    "href": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#sole-proprietorship",
    "title": "How to Release Your First iOS App",
    "section": "Sole Proprietorship",
    "text": "Sole Proprietorship\nIf you’re a solo developer in the U.S., like myself, working on your first app as a side hustle, you are technically a sole proprietor without the need to register anything with the government. However, please note that I am not a lawyer, and this is not legal advice. It’s important to consult with your local government to determine the requirements for establishing a sole proprietorship.\nAs a sole proprietor, it’s recommended to keep your personal and business finances separate by setting up a business bank account. Contrary to my initial expectations, obtaining a business bank account turned out to be much easier than anticipated. I opted for one from Novo, which offers zero monthly fees, zero minimum balance, and exclusive partner perks. My application was approved within a day.\nYou can use my referral link to receive $40 when opening a new account with Novo.\nHaving a business bank account will help you maintain separate records for your business transactions, simplifying the process during tax season."
  },
  {
    "objectID": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#app-preview",
    "href": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#app-preview",
    "title": "How to Release Your First iOS App",
    "section": "App Preview",
    "text": "App Preview\nWhen providing screenshots, it is important to adhere to specific sizes. To create visually appealing screenshots, you can utilize free tools such as https://app-mockup.com or https://app.flycricket.com.\nAdditionally, you may need to prepare screenshots for the 5.5” iPhone screen size."
  },
  {
    "objectID": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#privacy-policy",
    "href": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#privacy-policy",
    "title": "How to Release Your First iOS App",
    "section": "Privacy Policy",
    "text": "Privacy Policy\nAs a first-time app creator, I was unaware that releasing an app requires more than just the app itself. Creating a privacy policy seemed daunting, and I didn’t want to incur the expense of hiring a lawyer.\nAfter conducting some research, I came across the website https://app-privacy-policy-generator.firebaseapp.com, which has been utilized by many solo developers.\nYou can host your privacy policy for free on flycricket."
  },
  {
    "objectID": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#support-url",
    "href": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#support-url",
    "title": "How to Release Your First iOS App",
    "section": "Support URL",
    "text": "Support URL\nA support URL is a required element. Some people suggest that using a WordPress website, a Facebook page, or other social media pages is sufficient. However, I created a dedicated page for my app, which also serves as a marketing page.\nYou can use flycricket to create a support email."
  },
  {
    "objectID": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#marketing-assets",
    "href": "posts/2023-06-20-How_to_Release_Your_First_iOS_App.html#marketing-assets",
    "title": "How to Release Your First iOS App",
    "section": "Marketing Assets",
    "text": "Marketing Assets\nOnce your app is approved, you can obtain a link to the app and relevant marketing materials, including a QR code and the App Store badge, using the App Store Marketing Tools available at https://developer.apple.com/app-store/marketing/guidelines/."
  },
  {
    "objectID": "posts/2019-06-16-three-simple-steps-to-start-using-css-grid-template.html",
    "href": "posts/2019-06-16-three-simple-steps-to-start-using-css-grid-template.html",
    "title": "Three Simple Steps to Start Using CSS Grid Template",
    "section": "",
    "text": "First, we change the display to be “grid”:\ndiv.container {\n    display: grid;\n}"
  },
  {
    "objectID": "posts/2019-06-16-three-simple-steps-to-start-using-css-grid-template.html#step-1-display-grid",
    "href": "posts/2019-06-16-three-simple-steps-to-start-using-css-grid-template.html#step-1-display-grid",
    "title": "Three Simple Steps to Start Using CSS Grid Template",
    "section": "",
    "text": "First, we change the display to be “grid”:\ndiv.container {\n    display: grid;\n}"
  },
  {
    "objectID": "posts/2019-06-16-three-simple-steps-to-start-using-css-grid-template.html#step-2-define-grid",
    "href": "posts/2019-06-16-three-simple-steps-to-start-using-css-grid-template.html#step-2-define-grid",
    "title": "Three Simple Steps to Start Using CSS Grid Template",
    "section": "Step 2: Define Grid",
    "text": "Step 2: Define Grid\nWe then define the grid using “fr” (short for fraction) as the following:\ndiv.container {\n    display: grid;\n    grid-template-columns: 5fr 1fr 1fr;\n    grid-template-rows: 1fr 1fr;\n}\n\n\n\n\n\nThink of each fraction as 1 unit. So the above code defines a grid with 3 columns with width 5, 1, 1 respectively and two rows with equal height. One can also define the grid using px, percentages and other units, but I find “fr” to be very convenient."
  },
  {
    "objectID": "posts/2019-06-16-three-simple-steps-to-start-using-css-grid-template.html#step-3-place-content-into-the-grid",
    "href": "posts/2019-06-16-three-simple-steps-to-start-using-css-grid-template.html#step-3-place-content-into-the-grid",
    "title": "Three Simple Steps to Start Using CSS Grid Template",
    "section": "Step 3: Place Content Into the Grid",
    "text": "Step 3: Place Content Into the Grid\nThe easiest way is to use grid-template-areas:\ndiv.container {\n    display: grid;\n    grid-template-columns: 5fr 1fr 1fr;\n    grid-template-rows: 1fr 1fr;\n    grid-template-areas:\n        \"description social rss\"\n        \"description social rss\";\n}\n\ndiv.description {\n    grid-area: description;\n    justify-self: stretch;\n    align-self: stretch;\n}\ndiv.social {\n    grid-area: social;\n    justify-self: stretch;\n    align-self: stretch;\n}\ndiv.rss {\n    grid-area: rss;\n    justify-self: stretch;\n    align-self: stretch;\n}\nWe assign the grid-area attribute for each block that we want to place into the grid, and then use grid-template-areas to easily specify how they should be layed out within the grid. The justify-self and align-self attributes further specifies how they should be justified and aligned within their grid space.\nThat should get you started! It’s really that simple!\nFor more features and details about css grid, you can look up this wonderful guide: A Complete Guide to Grid."
  },
  {
    "objectID": "posts/2017-01-20-how-i-solved-the-worlds-hardest-logic-puzzle.html",
    "href": "posts/2017-01-20-how-i-solved-the-worlds-hardest-logic-puzzle.html",
    "title": "How I solved the world’s hardest logic puzzle",
    "section": "",
    "text": "People often show solutions to a problem without showing their thinking process, just like a magician hiding his/her methods. Instead of knowing the answer, which is no fun at all, I think it’s more important to understand the logical steps that help one reach the answer. After all, this is where the satisfaction of understanding comes from. So I thought it might be helpful to show the paths I took during my attempt to solve this puzzle."
  },
  {
    "objectID": "posts/2017-01-20-how-i-solved-the-worlds-hardest-logic-puzzle.html#i.-the-qualities-question-1-needs-to-satisfy",
    "href": "posts/2017-01-20-how-i-solved-the-worlds-hardest-logic-puzzle.html#i.-the-qualities-question-1-needs-to-satisfy",
    "title": "How I solved the world’s hardest logic puzzle",
    "section": "I. The Qualities Question 1 Needs to Satisfy:",
    "text": "I. The Qualities Question 1 Needs to Satisfy:\nLet’s take the mapping of “da” -&gt; “3 is not R” and “ja” -&gt; “2 is not R” as an example to start our reasoning. Since we don’t have to think about god 1=R, either 2 or 3 is R. The mapping reduces to “da” -&gt; “2 is R” and “ja” -&gt; “3 is R”.\nThis mapping requirement means no matter who (T or F) this question is asked, if the answer to “is 2 R” is yes, we should always get “da” as the answer, regardless of whether “da” means yes or no. If the answer to “is 2 R” is no, we should always get “ja” as the answer, regardless of what “ja” means.\nTo break this down further, we have\n\\[\\text{2 is not R} + \\left\\{ \\begin{matrix} \\text{da} =\\text{yes} \\Rightarrow \\text{yes (da)}\\\\ \\text{da}=\\text{no} \\Rightarrow \\text{no (da)} \\end{matrix}\\right.\\]\n\\[\\text{2 is R} + \\left\\{ \\begin{matrix} \\text{da}=\\text{yes} \\Rightarrow \\text{no (ja)}\\\\ \\text{da}=\\text{no} \\Rightarrow \\text{yes (ja)}\\end{matrix} \\right.\\]\n\nBoth T and F should give the same yes or no answer so that it doesn’t matter which god is answering the question.\nWhether “da” is yes or no should flip the yes or no answer, so that when “da” means yes, the god says “da” (yes), and when “da” means no, the god also says “da” (no).\nWhether “2 is R” should also flip the yes or no answer, so that “da” flips to “ja”."
  },
  {
    "objectID": "posts/2017-01-20-how-i-solved-the-worlds-hardest-logic-puzzle.html#ii.-construction-of-the-question",
    "href": "posts/2017-01-20-how-i-solved-the-worlds-hardest-logic-puzzle.html#ii.-construction-of-the-question",
    "title": "How I solved the world’s hardest logic puzzle",
    "section": "II. Construction of the Question:",
    "text": "II. Construction of the Question:\n\na. Satisfying Requirement 1:\nLet’s look at requirement 1 first: how is it possible to ask a question, such that both gods would give the same answer? Since for most simple questions, T and F would give opposite answers, we need to combine their answers in some way to get agreements. A simple trick that can achieve this immediately comes to mind: chain T’s answer with R’s answer with an embedded question.\n\nNote: This was also my downfall. As I will explain later, there’s another way of getting consistent answers between T and F gods that leads to a simpler overall solution. But I was so eager to test out this first strategy that came to my mind, that I didn’t explore other possibilities. Let me now continue my reasoning following this way of constructing the question.\n\nStill assuming we are only dealing with T and F, we can ask for example: “would the other god (one of T and F) answer yes to the question Q”? Question Q is just an embedded question. I will leave the details of the deduction to the readers, and just say no matter who answers the question (T or F) and who the other god is (F or T), if the truthful answer to Q is yes, then we will get a no answer, and vice versa, because F in the chain would flip the answer once.\n\n\nb. Satisfying Requirement 2:\nRequirement 2 introduced 2 different scenarios: “da” is yes or “da is no. And depending on which is the case, the answer changes. The solution is very easy, we just compound this element on top of the chaining question we constructed above. Simply change”yes” to “da” (or “ja”) to cover the ambiguity of “da”: “would the other god answer ‘da’ to the question Q”?\nWhen “da”=yes, the above question translates to the original “would the other god answer yes to the question Q”, when “da”=no, it translates to “would the other god answer no to the question Q”. The same chain structure guarantees the same answer between T and F gods as before, but now the answer also flips depending on the meaning of “da”.\n\n\nc. Satisfying Requirement 3:\n“is 2 R” should also flip the answer, which means we need to incorporate it into our question as well. Well, we haven’t specified what Q is yet. Any simple question can replace Q’s position and still meet requirements 1 and 2, and the truthful answer to this question Q would flip the chain since it changes the starting point of the chain. Therefore, the question now becomes: “would the other god answer ‘da’ to the question ‘is 2 R’”?\nAgain, I leave the detailed deduction of the answers in different scenarios to the readers.\n\n\nd. Dealing with the Random God\nThe question would work, except when we have a random god between 2 and 3, so we can’t simply say “the other god” to automatically pick out T or F from god 2 and god 3. But for our question to work, the answer to the question “is 2 R” has to be consistent and not random.\nThere’s no way that we can know which one of the other 2 gods is not R before the first question since that’s exactly what the first question is trying to figure out. If we think carefully though, we notice that we don’t need to identify which one of the other 2 gods is not R for our question to work. We only need the answer to be consistent. One way to do that is to combine the answers of the other two gods in such a way that only the non-random god’s answer is taken.\nHow to combine a consistent answer with a random answer so that the consistent answer is always taken? Well, we can use the phrase “always” to single out the consistent answer.\nThe question, therefore, becomes: “would at least one of the other 2 gods always answer ‘da’ to the question ‘is 2 R’”?"
  },
  {
    "objectID": "posts/2017-01-20-how-i-solved-the-worlds-hardest-logic-puzzle.html#i.-a-much-simpler-solution",
    "href": "posts/2017-01-20-how-i-solved-the-worlds-hardest-logic-puzzle.html#i.-a-much-simpler-solution",
    "title": "How I solved the world’s hardest logic puzzle",
    "section": "I. A Much Simpler Solution:",
    "text": "I. A Much Simpler Solution:\nAs mentioned in Step 3.II.a, there’s another way to achieve requirement 1. Instead of chaining T and R’s answers with each other, we chain them to themselves! After all, F and F double flip is the same as T and T. The question can be asked as “would you answer ‘da’ to the question …”\nThe good thing about this is that since we don’t need to consider the situation where we are asking the random god, the god we are asking can always be treated as non-random. Therefore, we don’t need to group this god with another god, and the question becomes much simpler:\n“Would you say ‘da’ to the question ‘is 2 the random god’”?\nNotice that this “would you say…” is an embedded question just like before “would the other god say…” It requires the god to answer about his answer to the question.\nThis dramatically simplifies the solution."
  },
  {
    "objectID": "posts/2017-01-20-how-i-solved-the-worlds-hardest-logic-puzzle.html#ii.-my-original-very-complicated-solution",
    "href": "posts/2017-01-20-how-i-solved-the-worlds-hardest-logic-puzzle.html#ii.-my-original-very-complicated-solution",
    "title": "How I solved the world’s hardest logic puzzle",
    "section": "II. My Original Very Complicated Solution",
    "text": "II. My Original Very Complicated Solution\nBesides the other chaining method, I didn’t think about, in my hurried effort to solve this puzzle, I also rushed to get to the end and ended up with a more complicated version of question 1. Instead of asking how the god would answer the question, I was so worried about dealing with the Random god that I also grouped two gods’ answers in constructing question Q. My original first question is unnecessarily more complicated:\n“Would at least one of the other 2 gods answer ‘da’ to the question ‘would one of you and god 2 always disagree to the question is da yes’”?\nIt should be easy to see that question Q “would one of you and god 2 always disagree about the question ‘is da yes’” really is just asking is “is one of you and god 2 R”? Since T and F would always disagree on the answer to that question. And since we can ignore the case that the god you are asking the question is R, this question simplifies to “is god 2 R”?\nI was in the mindset of grouping gods and forgot about the previous deduction that “one does not need to consider the situation that the god you are asking the first question is R”. This shows how important it is to go through the logical deduction steps more carefully."
  },
  {
    "objectID": "posts/2021-08-19-data-block-api-in-fastai.html",
    "href": "posts/2021-08-19-data-block-api-in-fastai.html",
    "title": "Understanding Fastai’s DataBlock API",
    "section": "",
    "text": "Fastai’s DataBlock API is a flexible and easy way to get and transform your data into something ready to be fed to a model. The documentation and tutorial give some good examples of how to use this API. However, I still find it unclear how each argument in Datablock influences the different steps in the data transformation process.\nIn this post, I will try to visualize the data transformation process and explain the different steps the DataBlock API can hook into. Hopefully, this will make it easier for people to customize this process using this API."
  },
  {
    "objectID": "posts/2021-08-19-data-block-api-in-fastai.html#introduction",
    "href": "posts/2021-08-19-data-block-api-in-fastai.html#introduction",
    "title": "Understanding Fastai’s DataBlock API",
    "section": "",
    "text": "Fastai’s DataBlock API is a flexible and easy way to get and transform your data into something ready to be fed to a model. The documentation and tutorial give some good examples of how to use this API. However, I still find it unclear how each argument in Datablock influences the different steps in the data transformation process.\nIn this post, I will try to visualize the data transformation process and explain the different steps the DataBlock API can hook into. Hopefully, this will make it easier for people to customize this process using this API."
  },
  {
    "objectID": "posts/2021-08-19-data-block-api-in-fastai.html#datablock-api-as-a-blueprint-for-data-transformation",
    "href": "posts/2021-08-19-data-block-api-in-fastai.html#datablock-api-as-a-blueprint-for-data-transformation",
    "title": "Understanding Fastai’s DataBlock API",
    "section": "DataBlock API as A Blueprint for Data Transformation",
    "text": "DataBlock API as A Blueprint for Data Transformation\nThe data transformation process constructed by Fastai is depicted as follows, where the colored steps can be configured through the DataBlock API:\n\n\n\nHow different parts of DataBlock API fit in the data loading process.\n\n\n\nget_item: This is the first optional function that takes the source as input, and returns items to be processed by the Datasets object in Fastai. If it’s not specified, the source will be passed directly to Datasets.\nsplitter: The splitter is a function that returns two lists of indices, one for the training data set and one for the validation data set so that Datasets and Dataloaders know how to split the data into train/valid.\ngetters (or get_x, get_y): getters are a list of functions that is applied to each item passed to them to generate corresponding x and y. You can also specify get_x and/or get_y specifically. They will overwerite getters as get_x + get_y. Note, the number of functions in get_x and get_y should be consistent with the number of x and y specified in blocks and n_inp (see below).\ntype_tfms: These are collected from your TranformBlocks you specified in blocks (explained below). They will transform your x and y respectively, according to the blocks you used for x and y.\nitem_tfms: A list of Transforms to be combined with the item_tfms in your TransformBlocks for x and y, respectively. These are applied to each item in the Dataloaders object before batches are created. For example, we can resize each image to the same size at this step.\nbatch_tfms: A list of Transforms to be combined with the batch_tfms in your TransformBlocks for x and y specified in blocks. These are applied after a batch is created.\n\n(Note that the Transforms need to be different based on what type of object it’s applied on, whether it’s the training or validation set. This is achieved through type dispatch and the split_idx variable in Transform respectively. Please see the next section Deeper Dive for more details.)\nAn example usage of the DataBlock API:\ndblock = DataBlock(\n    blocks=(ImageBlock, BBoxBlock, BBoxLblBlock), \n    n_inp=1, \n    get_items=get_image_files,\n    splitter=RandomSplitter(),\n    getters=None, \n    get_x=None,\n    get_y=[lambda o: img2bbox[o.name][0], lambda o: img2bbox[o.name][1]], \n    item_tfms=Resize(128),\n    batch_tfms=aug_transforms()\n)\n\ndls = dblock.dataloaders(path_to_image_folder)\n\nblocks: These can be TransformBlock objects that simultaneously specify the types of your x and y, and their associated type_tfms, item_tfms and batch_tfms to be inserted in the data transformation process for each type. The objects here do not HAVE TO be TransformBlock though. If they are not, they do not contribute any type_tfms, item_tfms and batch_tfms to the data transformation process.\nA TransformBlock is simply defined as:\nclass TransformBlock():\n    \"A basic wrapper that links defaults transforms for the data block API\"\n    def __init__(self, type_tfms=None, item_tfms=None, batch_tfms=None, dl_type=None, dls_kwargs=None):\n        self.type_tfms  =            L(type_tfms)\n        self.item_tfms  = ToTensor + L(item_tfms)\n        self.batch_tfms =            L(batch_tfms)\n        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)\nn_inp: This specifies the number of inputs (x) so that the API knows the first n_inp TransformBlock are for x and the rest for y. In this case, we have one x and two ys. The model will need to predict for both the bounding box and the label.\nitem_tfms, batch_ftms: additional Transforms to be combined with those specified in the TransformBlocks in blocks.\nget_items, splitter, getters, get_x, get_y have one-to-one correspondance to those explained in the blueprint.\n\nNow, we can do a quick walkthrough of the example dblock:\n\npath_to_image_folder is fed into get_image_files to generate a list of paths to all images.\nRandomSplitter() takes this list of paths and generates randomized lists of indices for train and valid data sets. These indices will be held in Datasets and Dataloaders to generate the final train/valid data.\nBecause get_x is not specified, these paths are passed through directly as our x at this point.\nThe same list of paths is passed to get_y which has two functions, one looking up the file name to find its corresponding bounding box data and the other the corresponding label. Because n_inp=1, we get two ys.\nThe list of paths in x is passed through type_tfms specified in ImageBlock to open the images. type_tfms in BBloxBlock and BBoxLablBlock are applied to the bounding box and label data respectively.\nThe item_tfms is appended to any item_tfms specified in ImageBlock, BBloxBlock, BBoxLablBlock respectively and then applied to our x and y to resize the images and the bounding box while leaving the label unchanged. (Again, a Transform object can specify different transformations to be applied to different object types.)\nFinally, after a batch is created we apply aug_transforms() to generate a list of fliped, rotated, zoomed, warped, lighting-adjusted images as augmentations of our data for training."
  },
  {
    "objectID": "posts/2021-08-19-data-block-api-in-fastai.html#deeper-dive",
    "href": "posts/2021-08-19-data-block-api-in-fastai.html#deeper-dive",
    "title": "Understanding Fastai’s DataBlock API",
    "section": "Deeper Dive",
    "text": "Deeper Dive\n\nTransform and Pipeline\nThe Transform object can have multiple encodes/decodes methods defined for different argument types. The appropriate encodes/decodes method will be chosen based on the first argument’s type. This is achieved through type dispatch. For this more advanced topic, please watch Jeremy Howard’s code walk-through video on how the Transform class is built:\n\nYou can find many examples in the Transform documentation. Here I only give the most basic demostrations of Transform:\n\nclass Times2(Transform):\n    def encodes(self, x):\n        return x*2\n    \n    def decodes(self, x):\n        return x/2\n\n@Transform\ndef plus3(x:int): return x+3\n\ntimes2 = Times2()\n# tests\ntest_eq(times2(1), 2)\ntest_eq(plus3(1), 4)\ntest_eq(plus3(1.0), 1)\n\nAs can be seen, the plus3 function is only applied to integer types.\nA Pipeline simply applies a list of Transforms to an item. You can optionally specify split_idx to turn on only transforms with the same split_idx. Please see the Pipeline doc for more details.\n\np = Pipeline([times2,plus3])\n# tests\ntest_eq(p(1), 5)\ntest_eq(p(1.0), 2)\n\n\n\nTfmdLists and Datasets\nTfmdLists applies a list of Transforms or a Pipeline to a list of items, with the option to split the list into training data set vs. validation data set by specifying splits as lists of indices:\n\ntf = TfmdLists([1, 2, 5], p, splits=[[0],[1,2]])\ntf.train[:]\ntf.valid[:]\n\n(#1) [5]\n\n\n(#2) [7,13]\n\n\nDatasets further expands the functionality so that you can specifiy multiple Pipelines or lists of Transforms to a list of items, returning a list of tuples with each item in the tuple corresponding to the result of one Pipeline.\n\nds = Datasets([1,2,5,-9,11,15], [p, [plus3]], splits=[[0, 1, 2, 3],[4, 5]])\nds.train\nds.valid\n\n(#4) [(5, 4),(7, 5),(13, 8),(-15, -6)]\n\n\n(#2) [(25, 14),(33, 18)]\n\n\nFrom Datasets, we can then get the dataloaders:\n\ndls = ds.dataloaders(bs=2, shuffle=False)\ndls.one_batch()\n\n(tensor([5, 7]), tensor([4, 5]))\n\n\nThe same could be achieve by using the DataBlock API directly:\n\ndblock = DataBlock(blocks = (TransformBlock(type_tfms=[times2, plus3]), \n                             TransformBlock(type_tfms=[plus3])),\n                   splitter=lambda x: [[0, 1, 2, 3, 4], [5]]\n                  )\n\ndls = dblock.dataloaders([1,2,5,-9,11,15], bs=2, shuffle=False)\ndls.one_batch()\n\n(tensor([5, 7]), tensor([4, 5]))"
  },
  {
    "objectID": "posts/2020-11-26-what_is_temporature.html",
    "href": "posts/2020-11-26-what_is_temporature.html",
    "title": "What is Temperature",
    "section": "",
    "text": "The concept of temperature has always been confusing to me. On the one hand, we have statistical mechanics that defines the temperature by \\(\\frac{1}{T} = \\left.\\frac{\\partial S}{\\partial E} \\right|_{V,N}\\) (or \\(T = \\left.\\frac{\\partial E}{\\partial S} \\right|_{V,N}\\)). On the other hand, we have our everyday experience of temperature scales. We obviously don’t measure the entropy of everything and do the partial derivative with respect to their energy to get their temperature. Instead we mark the temperature directly from a thermometer. How are they connected? How is that abstract temperature formula related to how we measure temperature in our everyday life?\nWhat on earth is temperature?\n\n\nIn Brief\n\n\n\nFrom statistical mechanics, we obtain a quantity that becomes equal when systems reach thermal equilibrium.\n\n\nHistorically, the temperature scale was defined empirically to be proportional to the volume of approximate ideal gas.\n\n\nBy connecting the ideal gas equation derived from statistical mechanics to the one obtained empirically, we can fix the temperature definition in statistical mechanics.\n\n\nWe then switch to adopt the temperature definition from statistical mechanics instead, which was fixed to be roughly consistent with the historical temperature scale.\n\n\nThis modern definition of temperature gives the most general meaning of temperature. All thermometers including the ones we use every day, in theory, should be calibrated by model systems that are calculable from statistical mechanics according to this new definition of temperature."
  },
  {
    "objectID": "posts/2020-11-26-what_is_temporature.html#introduction",
    "href": "posts/2020-11-26-what_is_temporature.html#introduction",
    "title": "What is Temperature",
    "section": "",
    "text": "The concept of temperature has always been confusing to me. On the one hand, we have statistical mechanics that defines the temperature by \\(\\frac{1}{T} = \\left.\\frac{\\partial S}{\\partial E} \\right|_{V,N}\\) (or \\(T = \\left.\\frac{\\partial E}{\\partial S} \\right|_{V,N}\\)). On the other hand, we have our everyday experience of temperature scales. We obviously don’t measure the entropy of everything and do the partial derivative with respect to their energy to get their temperature. Instead we mark the temperature directly from a thermometer. How are they connected? How is that abstract temperature formula related to how we measure temperature in our everyday life?\nWhat on earth is temperature?\n\n\nIn Brief\n\n\n\nFrom statistical mechanics, we obtain a quantity that becomes equal when systems reach thermal equilibrium.\n\n\nHistorically, the temperature scale was defined empirically to be proportional to the volume of approximate ideal gas.\n\n\nBy connecting the ideal gas equation derived from statistical mechanics to the one obtained empirically, we can fix the temperature definition in statistical mechanics.\n\n\nWe then switch to adopt the temperature definition from statistical mechanics instead, which was fixed to be roughly consistent with the historical temperature scale.\n\n\nThis modern definition of temperature gives the most general meaning of temperature. All thermometers including the ones we use every day, in theory, should be calibrated by model systems that are calculable from statistical mechanics according to this new definition of temperature."
  },
  {
    "objectID": "posts/2020-11-26-what_is_temporature.html#temperature-from-statistical-mechanics",
    "href": "posts/2020-11-26-what_is_temporature.html#temperature-from-statistical-mechanics",
    "title": "What is Temperature",
    "section": "Temperature from Statistical Mechanics",
    "text": "Temperature from Statistical Mechanics\n\nMicrostates and the principle of equal a priori probabilities\nTo understand temperature from statistical mechanics, we need the concepts of macro-state and micro-state. A system in thermodynamic equilibrium is said to be in a macrostate, whose characteristics such as energy, volume, pressure, and temperature are stable and can be directly measured. A macrostate is composed of many microstates which describe the detailed states of all particles in the system and are constantly transitioning into each other.\nThe analysis of statistical mechanics starts from the assumption that a system that has reached equilibrium is equally likely to be found in any of its accessible microstates. We call this the “principle of equal apriori probabilities”, the justification (not a complete proof) for which can be found here using the H theorem. For now, we take it as a given and know that statistical mechanics built on this assumption has worked remarkably well.\n\n\nThe most likely macrostate under thermal equilibrium\nLet’s imagine putting two systems \\(1\\) and \\(2\\) next to each other so that they can exchange energies. What the equal probability principle tells us is that when systems \\(1\\) and \\(2\\) reach equilibrium, the probability of what macroscopic states these two are in is proportional to the number of corresponding microscopic states there are for the combined system. Systems 1 and 2 are going to spend most of the time in macrostates that had lots of corresponding microstates.\nLet’s denote the number of microstates for a macrostate of \\(N\\) particles, with volume \\(V\\) and internal energy \\(E\\) as \\(\\Omega(N, V, E)\\). Then the number of microstates when A and B are together is\n\\[\\Omega(N, V, E) = \\sum_{E_1}\\Omega_{1}(N_1, V_1, E_1)\\Omega_{2}(N_2, V_2, E-E_1), \\]\nsumming over all possible values of \\(E_1\\le E\\). In this case, there’s no exchange of particles and no change of volume, so \\(N_1\\), \\(N_2\\), \\(V_1\\) and \\(V_2\\) are all fixed. (For people that have studied Thermodynamics, you may recognize that we are using Microcanonical Ensembles here.)\nThe probability of a macrostate where system \\(1\\) has energy \\(E_1\\) and system \\(2\\) has energy \\(E-E_1\\) is therefore\n\\[p(E_1) = \\Omega_{1}(N_1, V_1, E_1)\\Omega_{2}(N_2, V_2, E-E_1)/\\Omega(N, V, E).\\]\nWe will prove in Apendex I that the most likely macrostate dominates the probability distribution, and therefore the equilibrium states are very well represented by the energy distribution with the maximum probability.\nLet’s take a look at this maximum probability state. When \\(p\\) reaches the maximum, the the first order derivative vanishes:\n\\[\\left.\\frac{\\partial \\Omega_1}{\\partial E_1}\\right|_{N_1, V_1} \\Omega_2 dE_1 + \\left.\\frac{\\partial \\Omega_2}{\\partial E_2}\\right|_{N_2, V_2} \\Omega_1 dE_2 =0\\]\nBecause \\(dE_2=-dE_1\\), we obtain\n\\[\\left.\\frac{\\partial\\log \\Omega_1}{\\partial E_1}\\right|_{N_1, V_1} = \\left.\\frac{\\partial\\log \\Omega_2}{\\partial E_2}\\right|_{N_2, V_2} .\\]\nWe conclude that when thermal equilibrium is reached, the quantity \\(\\frac{\\partial\\log \\Omega}{\\partial E}\\) in systems 1 and 2 become equal. If this quantity in these two systems is not equal, then they haven’t reached equilibrium yet.\nObviously, this quantity is connected to our everyday concept of “temperature”. How is it connected to temperature? We don’t know yet. For now, we will just note that it’s a function of temperature \\(T\\):\n\\[f(T)=\\left.\\frac{\\partial\\log \\Omega}{\\partial E} \\right|_{N, V} = \\left.\\frac{\\partial\\bar{S}}{\\partial E}\\right|_{N, V},\\]\nwhere for convenience, I introduced the notation for “entropy”\n\\[\\bar{S}\\equiv\\log \\Omega.\\]\n(For our purpose in this post, we don’t have to get too deep into the meaning of “entropy”. Here we will merely take it as a mathematical expression.)\nWe see that that the partial derivative of entropy with respect to energy, when the number of particles and the volume are fixed, is a function of temperature. That’s all statistical mechanics can tell us. It leaves plenty of room for how one can define temperature. Even though not required for the following derivation, as an exercise, the reader can further determine that the function should decrease in value when temperature increases, using the fact that we are looking at a maximum here, where the second derivative is negative.\nTo connect this statistical mechanics concept of temperature to the concept of temperature used in our daily lives, we need to first take a detour and have a look at how the temperature was defined historically before thermodynamics."
  },
  {
    "objectID": "posts/2020-11-26-what_is_temporature.html#empirical-temperature-definition",
    "href": "posts/2020-11-26-what_is_temporature.html#empirical-temperature-definition",
    "title": "What is Temperature",
    "section": "Empirical Temperature Definition",
    "text": "Empirical Temperature Definition\nIt was discovered that different gases kept under very low constant pressure, when started at the same volume and the same temperature, expands to the same volume when the temperature changes (experimentally, we can make sure that temperatures are the same by putting the two gases in contact with the same heat reservoir). Temperature can therefore be taken as a quantity that increases linearly with the volume occupied by the gas: \\(T\\propto V\\).\n{% include image.html file=“https://upload.wikimedia.org/wikipedia/commons/e/e4/Charles_and_Gay-Lussac%27s_Law_animated.gif” caption=” If we mark the temperature scales proportional to the volumes’ scales, we get a basic gas thermometer.” %}\nPeople also discovered that when the volume is kept constant, the pressure increases linearly with the temperature: \\(P \\propto T\\); when the temperature is kept constant, the pressure is inversely proportional to the volume: \\(P \\propto 1/V\\); and the volume of gas is proportional to the amount of gas: \\(V \\propto N\\).\nCombining all these observations, we get the combined gas law in a general form:\n\\[PV=kNT+c\\]\nNote that \\(k\\) and \\(c\\) are up to how we define the temperature scale:\n\nWe have the freedom to define the unit of temperature, i.e. how much one degree means. This affects the slope \\(k\\).\nWe have the freedom to define the starting point of temperature, i.e. where temperature 0 lies. This affects the constant \\(c\\).\n\nHistorically, people have defined the temperature scale in such a way that the difference between the boiling point and the triple point of water at one atmosphere of pressure is equal to 100. This defines the “degree” and determines the Boltzmann constant \\(k=8.31 J⋅K^{−1}⋅mol^{−1}\\).\nTo remove the constant in the equation, so that when the temperature reaches 0, it corresponds to \\(P=0\\) or \\(V=0\\), the “absolute zero” temperature can be defined in the following way:\nIf the triple point of water under the pressure of 1 atmosphere is \\(T_1\\), then the “zero temperature” \\(T_0\\) can be obtained by \\(PV=kN(T_1-T_0)\\), where \\(P\\) and \\(V\\) are the pressure and volume of an ideal gas at \\(T_1\\). This gives us the temperature difference between the freezing point of water and the “absolute zero” in the “degree” units, which comes out to be around \\(273.16\\) degrees. We then shift the temperature scales, so that the freezing point of water is at about \\(273.16\\) degrees and the “absolute zero” is at \\(0\\) degrees. This gives us the Kevin Temperature Scale.\nWith these two definitions, we’ve fixed our ideal gas equation:\n\\[PV = kNT\\]\nwhere \\(k=8.31 J⋅K^{−1}⋅mol^{−1}\\).\nNext, we want to connect this empirically defined temperature back to our temperature concept from statistical mechanics."
  },
  {
    "objectID": "posts/2020-11-26-what_is_temporature.html#connecting-the-statistical-temperature-with-the-empirical-temperature",
    "href": "posts/2020-11-26-what_is_temporature.html#connecting-the-statistical-temperature-with-the-empirical-temperature",
    "title": "What is Temperature",
    "section": "Connecting the Statistical Temperature with the Empirical Temperature",
    "text": "Connecting the Statistical Temperature with the Empirical Temperature\n\nFormula for pressure\nTo connect the two, we need to derive the ideal gas equation from statistical mechanics. And in order to do that, we need to know how pressure is connected to the concept of entropy.\nFrom the previous section on statistical mechanics, we see that the change of entropy contributes to the change of energy: \\(dE = f(T)d\\bar{S}\\) when \\(V\\) and \\(N\\) are fixed. This is the heat exchange discussed in that section. We also know that when volume changes, pressure does work and contributes to the energy of the system, if there’s no heat exchange: \\(dE=PdV\\).\nCombining them, we have\n\\[dE = PdV + f(T)d\\bar{S}.\\]\nTherefore, the pressure can be obtained through entropy in the following way\n\\[P = \\left. f(T)\\frac{\\partial \\bar{S}}{\\partial V} \\right|_{N, E}\\]\n\n\nDetermine the temperature function\nI will skip the derivation, which can be found in other textbooks. The number of microstates for an ideal gas at a constant energy \\(E\\) is 1\n\\[\\Omega(E) = V^N \\left(\\frac{3N}{2E}\\right)\\pi^{3N/2}(2mE)^{3N/2}/(3N/2)!\\]\nTherefore\n\\[P=f(T)\\left.\\frac{\\partial \\bar{S}}{\\partial V} \\right|_{N, E} = f(T)\\frac{N}{V}\\]\nComparing this to the ideal gas equation, we then have\n\\[f(T) = kT.\\]\nAt this point, we can plug this back into the relationship between entropy and energy to obtain\n\\[\\frac{1}{T} = \\left.k\\frac{\\partial\\bar{S}}{\\partial E}\\right|_{N, V}= \\left.\\frac{\\partial S}{\\partial E}\\right|_{N, V},\\]\nwhere we’ve also used the official definition of entropy which absorbs Boltzmann constant \\(k\\)\n\\[S=k\\bar{S} = k\\log \\Omega.\\]\nThe statistical mechanics’ definition of temperature that matches up with our historical empirical definition of temperature is therefore\n\\[\\frac{1}{T} = \\left.\\frac{\\partial S}{\\partial E}\\right|_{N, V}\\]\nor\n\\[T = \\left.\\frac{\\partial E}{\\partial S}\\right|_{N, V}.\\]"
  },
  {
    "objectID": "posts/2020-11-26-what_is_temporature.html#temperature-scale",
    "href": "posts/2020-11-26-what_is_temporature.html#temperature-scale",
    "title": "What is Temperature",
    "section": "Temperature Scale",
    "text": "Temperature Scale\n\nProblem with the old temperature scale\nWe obtained the statistical mechanics’ definition of temperature by connecting statistical mechanics equations to the empirical definition of temperature. This constrains the degree of freedom allowed by statistical mechanics and gives us a clear definition.\nHowever, the constant \\(k\\) now absorbed in the entropy \\(S\\) comes from the definition of a degree, which has to be determined by experiments first.\nOriginally, a degree is defined by dividing the temperature differences between the boiling point and the triple point of water. This requires two experimental measurements at two temperatures. To simplify this a little, we can define the temperature scale as the temperature of the triple point of water divided by \\(273.16\\).\nThis removes one of the measurements required since the absolute zero is theoretically simple from statistical mechanics, and fixes the temperature of the triple point to be exactly \\(T=273.16 K\\). We now only need to measure the \\(P\\), \\(V\\) and \\(N\\) in order to figure out the value of \\(k\\). If we are using gas, and it can be approximated as an ideal gas, then we can use the formula \\(PV=NkT\\) to determine the value of \\(k\\).\nOther substances can be used for this measurement too. The general principle here is to use certain model systems that are sufficiently simple so that one can calculate its entropy as a function of the energy, \\(S=S(E)\\), and derive the formula for its temperature. We then measure related quantities of the system to determine the value of \\(k\\).\nNotice that this requires a simple model system that’s calculable and a real system that’s close enough to the theoretical model system for precise measurements. This makes it very hard to determine the value of \\(k\\) to high precision.\nIn fact, because of this approach, the Boltzmann constant \\(k\\) was one of the least accurately known fundamental constants.\n\n\nRe-define the temperature scale\nIn 2019, the definition of temperature scale has been revised to fix this problem. Instead, we fix the value of \\(k\\) first and then use the temperature equation from statistical mechanics to define our temperature scale. This way, the Boltzmann constant can be defined exactly by other physical constants. For more details, please see redefinition of Boltzmann’s constant and its impacts on the definition of 1 Kevin.\n\n\nThe most general meaning of temperature\nNow that we switched to using statistical mechanics as the first principle for defining temperature scales, this means, the most general interpretation of temperature is that it’s the derivative of exchanged heat with respect to the entropy, i.e. the quantity that becomes equal under thermal equilibrium. Only in special situations, such as with the ideal gas, the temperature represents the average kinetic energy of atoms in the gas, because there the temperature is proportional to the average energy. But this is not always the case for other more complicated systems.\n\n\nThermometers\nHow is the temperature scale connected to the thermometers we use in our daily lives?\nBecause we now use the statistical mechanics’ definition of temperature as the official definition of temperature scales, in theory, all thermometers need to be calibrated to be consistent with the \\(T=\\left.\\partial E /\\partial S \\right|_{N, V}\\) formula. However, the entropies for most systems are too complicated to calculate.\nIdeally, we should use model systems that are calculable as our primary thermometers. Ideal gas, black body radiation, and spin paramagnetism are the three most important model systems that can be used as primary thermometers 2. In practice, we use systems that are very close to these ideal systems as our primary thermometers.\nWe then use these primary thermometers to calibrate secondary thermometers, which include most of the thermometers we use in our daily lives."
  },
  {
    "objectID": "posts/2020-11-26-what_is_temporature.html#appendix",
    "href": "posts/2020-11-26-what_is_temporature.html#appendix",
    "title": "What is Temperature",
    "section": "Appendix",
    "text": "Appendix\n\nI. why do we only focus on the most likely scenario?\nOne can prove that the entropy of a combined system equals the sum of its parts:\n\\[\\bar{S} = \\log \\Omega = \\log \\Omega_1 \\Omega_2 = \\log \\Omega_1 + \\log \\Omega_2 = \\bar{S}_1 + \\bar{S}_2,\\]\nTherefore, entropy is an extensive quantity, proportional to the size of the system: \\(\\bar{S} \\propto N\\), just as \\(U \\propto N\\).\nNow we can use this to prove that the probability drops dramatically when the energy distribution between systems 1 and 2 differ slightly from the most likely energy distribution.\nWe Talyor expand the numerator in probability \\(p\\) around the maximum \\(U_1=U_1^{*}\\):\n\\[\n\\begin{aligned}\n\\Omega_1(U_1)\\Omega_2(U-U_1)&=\\exp(\\bar{S}_1(U_1) + \\bar{S}_2(U-U_1)) \\\\\n&\\approx \\exp\\left(\\bar{S}_1(U_1^{*}) + \\frac{1}{2} (U_1-U_1^*)^2 \\frac{\\partial^2 \\bar{S}_1}{\\partial U_1^2} + \\bar{S}_2(U-U_1^{*}) + \\frac{1}{2} (U_1-U_1^*)^2 \\frac{\\partial^2 \\bar{S}_2}{\\partial U_2^2}\\right) \\\\\n&=\\Omega_1(U_1^*)\\Omega_2(U_2^*)\\exp\\left( \\frac{1}{2}(U_1-U_1^*)^2 \\left(\\frac{\\partial^2 \\bar{S}_1}{\\partial U_1^2} + \\frac{\\partial^2 \\bar{S}_2}{\\partial U_2^2}\\right) \\right)\n\\end{aligned}\n\\]\nwhere the terms linear in \\(U_1-U^\\ast_1\\) cancel out due to the fact that the temperature related quantity reaches balance at \\(U_1^{*}\\): \\(\\frac{\\partial \\bar{S}_1}{\\partial U_1} = \\frac{\\partial \\bar{S}_2}{\\partial U_2}\\).\nBecause \\(\\bar{S} \\propto N\\) and \\(U \\propto N\\), \\(\\frac{\\partial^2 \\bar{S}_1}{\\partial U_1^2} + \\frac{\\partial^2 \\bar{S}_2}{\\partial U_2^2} \\propto -1/N\\) (the second order derivative around the maximum is negative), the exponential part becomes a gaussian distribution \\(\\propto \\exp(\\frac{-(U_1-U_1^*)^2}{2N}) \\rightarrow \\exp(-N \\Delta \\epsilon^2/2)\\), where \\(\\Delta \\epsilon\\) is the average energy difference from the maximum per particle. When the number of particles \\(N\\) is large, this is a super narrow distribution, as an example:\n\n\n\n\n\nIn reality, this distribution is often so sharp that the other states with energies different from the states at the maximum have negligible probabilities, and the system is dominated by the state with the maximum probability."
  },
  {
    "objectID": "posts/2020-11-26-what_is_temporature.html#footnotes",
    "href": "posts/2020-11-26-what_is_temporature.html#footnotes",
    "title": "What is Temperature",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee derivations for Eqn. (3.48) in Statistical Mechanics: Entropy, Order Parameters, and Complexity by James P. Sethna.↩︎\nAppendix B in Thermo Physics by Charles Kittle.↩︎"
  },
  {
    "objectID": "posts/2022-07-02-Duck_Pass_Trail.html",
    "href": "posts/2022-07-02-Duck_Pass_Trail.html",
    "title": "Everything You Need to Know About Hiking the Duck Pass Trail",
    "section": "",
    "text": "Stats\n(The following stats are based my person experience for your reference.)\nWhen: July 2, 2022 (Saturday)\nCompletion Time: 6.5 hrs (8:30 am ~ 3 pm)\nParking: There was still a decent amount of parking spots at 8:20 am when I arrived. If you intend to return through the Emerald Lake Trail, you can also park at the nearby parking lot by the Emerald Lake Trailhead.\nFee: This trail is free for day-hike. However, you need a backcountry permit if you plan on staying overnight.\nRestrooms: There are restrooms at the trailhead parking lot but not on the trail.\nDistance: 9.5-mile R.T.\nElevation: 9,128 feet to 10,800 feet\nWeather: Sunny day ( 61 F ~ 72 F for my hike ). It was a bit chilly in the morning when I started at 8:30 am, but it quickly warmed up. Plus the strenuous climb, I don’t think a jacket is needed at this time of year from my personal experience. It even got a bit hot near noon when I was under constant sunlight climbing to Duck Lake.\n\n\nThings to Pack\n\n3 liters of water\nI actually packed two 2 gallons of water, and quickly regretted it due to the heavy weight. So I poured out 1 gallon, and didn’t even finish the other gallon by the end of the hike, despite constant hydration. 3 liters of water would’ve been enough for me.\nBattery Pack\nIf you plan to take lots of photos and videos (you should), you will definitely need a battery pack to recharge your phone.\nSunglasses\nLunch\nI packed some energy bars and some beef jerky. You can find some great spots at Duck Lake to enjoy your lunch before heading back.\nSunscreen\nYou will need this. Don’t forget to reapply every 2~3 hours.\nDownload the offline google map for this area!\nYou won’t have any cellphone signals during the hike. Having a map on your phone with your GPS on would help you know how far along you are in the hike.\n\nThings I didn’t pack but could be helpful\n\nMosquito Repellent\nI didn’t pack this, and was a bit regretting it. There were lots of mosquitos especially near the lakes. You may not want to add that to the weight. In that case, I would say at least remember to apply some mosquito repellent before heading out.\nHiking sticks\nI didn’t use hiking sticks, but I can see how that would be of great help to people, especially on the strenuous climb to the Duck Lake, and if you are heading back through the Emerald Lake Trail, which is very steep."
  },
  {
    "objectID": "posts/2019-09-22-how-to-write-the-setup.py-file-for-python-packages.html",
    "href": "posts/2019-09-22-how-to-write-the-setup.py-file-for-python-packages.html",
    "title": "How to Write the setup.py File for Python Packages",
    "section": "",
    "text": "The documentation for the setup.py file is not very clear, and I think the quickest way to learn this is through an example, so here is an example of some of the minimum things to configure in the setup.py:\nIf your folder structure is the following (see here for why this structure is preferred):\n- Project_folder\n- src\n- PACKAGE_NAME\n      - __init__.py\n      - data\n      - ...\n- test\n- setup.py\nwe can use the following setup.py.\nfrom setuptools import setup, find_packages\n\nsetup(name=PACKAGE_NAME,\n      maintainer=AUTHOR,\n      version=PACKAGE_VERSION,\n      install_requires=['pandas', 'numpy'],\n      package_dir={'': 'src'},\n      packages=find_packages('src'),\n      package_data={PACKAGE_NAME: ['data/*']},\n      include_package_data=True,\n      description=DESCRIPTION,\n      python_requires='&gt;=3.6')\n\nThe name, maintainer, and version are self-explanatory.\ninstall_requires specifies the dependent python packages so that when installing your package, if some of these packages are not already installed in the user’s system, they will be downloaded and installed. One can specify version requirements for each package here too.\npackages specifies all packages to include1. They should be specified in the form of [foo, foo.bar, foo.tar, foo.bar.tool, ...], where foo.bar, foo.tar and foo.bar.tool are sub-packages. All sub-packages need to be listed explicitly.\nIf you put all packages under one folder, you can use the find_packages function to automatically find all packages under that folder.\npackage_dir specifies where your package resides. The keys to this dictionary are package names, and an empty package name stands for the root package. In the above example, your package directly resides below the src folder.\nIf we have package_dir={'foo': 'lib'}, then it means the package foo is the folder lib. If we then have packages = ['foo', 'foo.bar'], Distutils will be looking for lib/__init__.py and lib/bar/__init__.py for the foo and foo.bar packages respectively.\npackage_data specifies data files to be included for each package. The key is the package name and the value is a list of paths to the data files that relative to the directory containing the package (information from the package_dir mapping is used if appropriate)."
  },
  {
    "objectID": "posts/2019-09-22-how-to-write-the-setup.py-file-for-python-packages.html#basic-setup",
    "href": "posts/2019-09-22-how-to-write-the-setup.py-file-for-python-packages.html#basic-setup",
    "title": "How to Write the setup.py File for Python Packages",
    "section": "",
    "text": "The documentation for the setup.py file is not very clear, and I think the quickest way to learn this is through an example, so here is an example of some of the minimum things to configure in the setup.py:\nIf your folder structure is the following (see here for why this structure is preferred):\n- Project_folder\n- src\n- PACKAGE_NAME\n      - __init__.py\n      - data\n      - ...\n- test\n- setup.py\nwe can use the following setup.py.\nfrom setuptools import setup, find_packages\n\nsetup(name=PACKAGE_NAME,\n      maintainer=AUTHOR,\n      version=PACKAGE_VERSION,\n      install_requires=['pandas', 'numpy'],\n      package_dir={'': 'src'},\n      packages=find_packages('src'),\n      package_data={PACKAGE_NAME: ['data/*']},\n      include_package_data=True,\n      description=DESCRIPTION,\n      python_requires='&gt;=3.6')\n\nThe name, maintainer, and version are self-explanatory.\ninstall_requires specifies the dependent python packages so that when installing your package, if some of these packages are not already installed in the user’s system, they will be downloaded and installed. One can specify version requirements for each package here too.\npackages specifies all packages to include1. They should be specified in the form of [foo, foo.bar, foo.tar, foo.bar.tool, ...], where foo.bar, foo.tar and foo.bar.tool are sub-packages. All sub-packages need to be listed explicitly.\nIf you put all packages under one folder, you can use the find_packages function to automatically find all packages under that folder.\npackage_dir specifies where your package resides. The keys to this dictionary are package names, and an empty package name stands for the root package. In the above example, your package directly resides below the src folder.\nIf we have package_dir={'foo': 'lib'}, then it means the package foo is the folder lib. If we then have packages = ['foo', 'foo.bar'], Distutils will be looking for lib/__init__.py and lib/bar/__init__.py for the foo and foo.bar packages respectively.\npackage_data specifies data files to be included for each package. The key is the package name and the value is a list of paths to the data files that relative to the directory containing the package (information from the package_dir mapping is used if appropriate)."
  },
  {
    "objectID": "posts/2019-09-22-how-to-write-the-setup.py-file-for-python-packages.html#why-do-we-choose-the-src-structure",
    "href": "posts/2019-09-22-how-to-write-the-setup.py-file-for-python-packages.html#why-do-we-choose-the-src-structure",
    "title": "How to Write the setup.py File for Python Packages",
    "section": "Why do we choose the “src” structure?",
    "text": "Why do we choose the “src” structure?\n\nWe could’ve put our package directly under the project folder:\n- Project_folder\n- PACKAGE_NAME\n      - __init__.py\n      - data\n      - ...\n- test\n- setup.py\nBut then when we write our tests, the local package with the same PACKAGE_NAME will be imported instead of the installed package in our system.\nWe could’ve put the content of our package directly under the src folder instead of having another folder with our package name:\n- Project_folder\n  - src\n    - __init__.py\n    - data\n    - ...\n  - test\n  - setup.py\nThis way, when we import PACKAGE_NAME, it won’t import the local package since they are under the folder named src. However, if we had done so, we would not only need to specify that package_dir={PACKAGE_NAME: 'src'}, but because the package name wouldn’t be picked up by the find_packages function, we would also need to manually list all packages in packages.\nWe could’ve put the test inside the package:\n- Project_folder\n  - src\n    - __init__.py\n    - data\n    - test\n    - ...\n  - setup.py\nBut then we would be distributing the test as part of the package, which is not ideal.\n\nIn comparison, the structure we mentioned in the very beginning avoids all these problems and is therefore what I consider the best solution I’ve found so far."
  },
  {
    "objectID": "posts/2019-09-22-how-to-write-the-setup.py-file-for-python-packages.html#footnotes",
    "href": "posts/2019-09-22-how-to-write-the-setup.py-file-for-python-packages.html#footnotes",
    "title": "How to Write the setup.py File for Python Packages",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nsee here for discussions on the difference between packages and modules.↩︎"
  },
  {
    "objectID": "posts/2022-12-23-Eclipse_on_pandora_and_orbital_physics.html",
    "href": "posts/2022-12-23-Eclipse_on_pandora_and_orbital_physics.html",
    "title": "Eclipse on Pandora and the Orbital Physics in Avatar",
    "section": "",
    "text": "After watching Avatar: The Way of Water, I’m quite intrigued by the eclipse in the movie. The sun is blocked by the gas giant for what appears to be a couple of hours, which seems to make sense if you assume that the sun travels across the sky in a similar amount of time as what we experience on Earth.\nHowever, on a deeper thought, the situation here is more complicated than that.\nThe fact that we have sunrise and sunset on Earth is because of the Earth’s rotation, and the eclipse only lasts a short while because the moon is very small in the sky, and its shadow does not cover the whole Earth.\nBut on Pandora, the gas giant it’s orbiting around is much bigger, and if we use Jupiter and its moons as a reference, then the shadow of the gas giant is probably bigger than Pandora. In that case, the spinning of Pandora does not get it out of the “shadow zone”. It can only get out of the shadow when Pandora travels across the gas giant’s shadow.\nSo now the question is, in this case, is it possible that the Eclipse only lasts a few hours? Here’s my analysis of this system, with some of the simplest assumptions"
  },
  {
    "objectID": "posts/2022-12-23-Eclipse_on_pandora_and_orbital_physics.html#shadow-size-of-the-gas-giant",
    "href": "posts/2022-12-23-Eclipse_on_pandora_and_orbital_physics.html#shadow-size-of-the-gas-giant",
    "title": "Eclipse on Pandora and the Orbital Physics in Avatar",
    "section": "Shadow Size of the Gas Giant",
    "text": "Shadow Size of the Gas Giant\n\n\n\n\n\nIf the sun for the gas giant and Pandora have a similar apparent size in the sky as our sun, then the ratio of its radius \\(R_s\\) to its distance \\(D\\) is about: \\[\\frac{R_s}{D}\\approx\\tan(0.53^{\\circ}) \\approx \\frac{1}{100}\\]\nWith similar triangles, we have \\[d = \\frac{DR}{R_s-R} \\approx \\frac{100R_sR}{R_s-R}\\]\nWe now do an order-of-magnitude estimation. Assuming that the sun is at least about 10 times bigger than the gas giant (you can get to this conclusion by looking up the size of Jupiter, our sun, Alpha Centauri A and use the fact that the gas giant here is smaller than Jupiter), we have \\(R_s/(R_s-R)\\approx 1\\) and \\[d \\approx 100R \\]\nUsing similar triangles again, we have the shadow radius \\[R_{shadow} = (d-r)R/d \\]\nWe’ve estimated that Pandora’s orbit radius around the gas giant \\(r \\lesssim 11.4 R\\), an order of magnitude less than \\(d\\), so the shadow radius \\[R_{shadow} \\approx R\\]"
  },
  {
    "objectID": "posts/2019-01-07-auto-generate-data-science-report-for-sharing.html",
    "href": "posts/2019-01-07-auto-generate-data-science-report-for-sharing.html",
    "title": "Export Jupyter Document With Optional Code Visibility",
    "section": "",
    "text": "Jupyter notebooks are great for data analysis, but when we need to share the analysis, some people may not care about the code. It would be great to have a solution that automatically generates reports where the code can be toggled by a button. After some online searching and experimentation, the following is my solution."
  },
  {
    "objectID": "posts/2019-01-07-auto-generate-data-science-report-for-sharing.html#why",
    "href": "posts/2019-01-07-auto-generate-data-science-report-for-sharing.html#why",
    "title": "Export Jupyter Document With Optional Code Visibility",
    "section": "",
    "text": "Jupyter notebooks are great for data analysis, but when we need to share the analysis, some people may not care about the code. It would be great to have a solution that automatically generates reports where the code can be toggled by a button. After some online searching and experimentation, the following is my solution."
  },
  {
    "objectID": "posts/2019-01-07-auto-generate-data-science-report-for-sharing.html#add-button-to-toggle-code",
    "href": "posts/2019-01-07-auto-generate-data-science-report-for-sharing.html#add-button-to-toggle-code",
    "title": "Export Jupyter Document With Optional Code Visibility",
    "section": "Add Button to Toggle Code",
    "text": "Add Button to Toggle Code\nJupyter notebooks are web-based, we can simply add some HTML and javascript to make this work. One can include a raw cell at the beginning of your notebook containing the JavaScript and HTML below. This code is heavily based on Chris Said’s blog post, except it also hides a few other things besides the input cell, including the numerical prompt next to the cells such as input [1] and output [1].\n&lt;script&gt;\nfunction code_toggle() {\n    if (code_shown){\n    $('div.input').hide('500');\n    $('#toggleButton').val('Show Code')\n    } else {\n    $('div.input').show('500');\n    $('#toggleButton').val('Hide Code')\n    }\n    code_shown = !code_shown\n}\n\n$( document ).ready(function() {\n    code_shown=false;\n    $('div.input').hide();\n    $('div.prompt').hide();\n    $('div.back-to-top').hide();\n    $('nav#menubar').hide();\n    $('.breadcrumb').hide();\n    $('.hidden-print').hide();\n});\n&lt;/script&gt;\n&lt;form action=\"javascript:code_toggle()\"&gt;\n&lt;input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"&gt;\n&lt;/form&gt;\nWhen we export the notebook to HTML, the added code will make a toggle button. See Chris’ example here.\nThis is good and all, but we don’t want to manually add this raw cell to every notebook we create. Plus, it takes up a lot of space and does not look good in the notebook format. Is there a way that Jupyter can automatically add this code to the HTML file when exporting?\nThe answer is yes."
  },
  {
    "objectID": "posts/2019-01-07-auto-generate-data-science-report-for-sharing.html#custom-template-for-exporting-html-file",
    "href": "posts/2019-01-07-auto-generate-data-science-report-for-sharing.html#custom-template-for-exporting-html-file",
    "title": "Export Jupyter Document With Optional Code Visibility",
    "section": "Custom Template for Exporting HTML File",
    "text": "Custom Template for Exporting HTML File\nMost people know that we can use nbconvert to export HTML file, but few know that we can choose a template to use during this process: jupyter nbconvert --to html 'example.ipynb' --template=custom_template.tpl\nThis effectively gives us unlimited flexibility to format the output HTML file however we want. (For more details on how to make a custom template, please refer to the official document on customizing nbconvert and the Jinja2 template language guide.)\nUnfortunately, I found that we can not directly inherit the existing template used by nbconvert, since the position we want to insert our toggle button is not available if we inherit the existing templates. We have to alter some of the existing templates to create our own.\nIf your Jupyter is installed using anaconda in a python3.6 environment called py3, then the default templates for generating HTML files can be found under the path:\n&lt;Anaconda_Folder&gt;/envs/py3/lib/python3.6/site-packages/nbconvert/templates/html/.\n\nI copied the full.tpl template and added the script part in the &lt;head&gt; element:\n#| code-fold: true\n{%- block toggle_script -%}\n&lt;script&gt;\nfunction code_toggle() {\n    if (code_shown){\n    $('div.input').hide('500');\n    $('#toggleButton').val('Show Code')\n    } else {\n    $('div.input').show('500');\n    $('#toggleButton').val('Hide Code')\n    }\n    code_shown = !code_shown\n}\n\n$( document ).ready(function(){\n    code_shown=false;\n    $('div.input').hide();\n    $('div.prompt').hide();\n    $('div.back-to-top').hide();\n    $('nav#menubar').hide();\n    $('.breadcrumb').hide();\n    $('.hidden-print').hide();\n});\n&lt;/script&gt;\n{%- endblock toggle_script -%}\nand the HTML part for the button to the body.\n&lt;body&gt;\n  &lt;div tabindex=\"-1\" id=\"notebook\" class=\"border-box-sizing\"&gt;\n    &lt;div class=\"container\" id=\"notebook-container\"&gt;\n        &lt;form action=\"javascript:code_toggle()\"&gt;\n        &lt;input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"&gt;\n        &lt;/form&gt;\n        {{ super() }}\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/body&gt;\nSee this gist for the full template code."
  },
  {
    "objectID": "posts/2019-01-07-auto-generate-data-science-report-for-sharing.html#use-jupyters-post-save-hook-to-automate",
    "href": "posts/2019-01-07-auto-generate-data-science-report-for-sharing.html#use-jupyters-post-save-hook-to-automate",
    "title": "Export Jupyter Document With Optional Code Visibility",
    "section": "Use Jupyter’s Post-Save Hook to Automate",
    "text": "Use Jupyter’s Post-Save Hook to Automate\nWe can add a function in the Jupyter configuration file to automatically export HTML file whenever we save a notebook. The Jupyter configuration file can be found at “~/.jupyter/jupyter_notebook_config.py” on mac.\nAn example code for jupyter_notebook_config.py that exports an HTML file on save for notebooks with “Report-” in their names:\nimport os\nfrom subprocess import check_call\n\ndef post_save(model, os_path, contents_manager):\n    \"\"\"post-save hook for converting notebooks to .py scripts\"\"\"\n    if model['type'] != 'notebook':\n        return # only do this for notebooks\n    d, fname = os.path.split(os_path)\n    if 'Report-' in fname:\n        # generate html files\n        check_call(['jupyter', 'nbconvert', '--to', 'html',\n            fname, '--template=report.tpl'], cwd=d)\n        print(\"finished creating html file {}\".format(fname.replace('.ipynb', '.html')))\n\n\nc = get_config()\nc.FileContentsManager.post_save_hook = post_save\nc.NotebookApp.open_browser = False\nSee Jupyter documentation on file save hooks for more details on how to use save hooks."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "How to Release Your First iOS App\n\n\n\n\n\n\n\nProgramming\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2023\n\n\nZiyue Li\n\n\n\n\n\n\n  \n\n\n\n\nEclipse on Pandora and the Orbital Physics in Avatar\n\n\n\n\n\n\n\nPhysics\n\n\n\n\nA physics study of eclipse by a gas giant seen from its moon.\n\n\n\n\n\n\nDec 23, 2022\n\n\nziyue li\n\n\n\n\n\n\n  \n\n\n\n\nTips for Configuring a Quarto Website\n\n\n\n\n\n\n\nWeb\n\n\n\n\n\n\n\n\n\n\n\nNov 24, 2022\n\n\nziyue li\n\n\n\n\n\n\n  \n\n\n\n\nEverything You Need to Know About Hiking the Duck Pass Trail\n\n\n\n\n\n\n\nTravel\n\n\n\n\nHopefully everything you need for planning this beautiful hike.\n\n\n\n\n\n\nJul 2, 2022\n\n\nZiyue Li\n\n\n\n\n\n\n  \n\n\n\n\nUnderstanding Fastai’s DataBlock API\n\n\n\n\n\n\n\nData Science\n\n\n\n\nA visualization and explanation of how the DataBlock API hooks into different steps of the data transformation process to make it customizable.\n\n\n\n\n\n\nAug 28, 2021\n\n\nZiyue Li\n\n\n\n\n\n\n  \n\n\n\n\nWhat is Temperature\n\n\n\n\n\n\n\nPhysics\n\n\n\n\nThe most general interpretation of temperature and how its definition and scale have evolved.\n\n\n\n\n\n\nNov 26, 2020\n\n\nZiyue Li\n\n\n\n\n\n\n  \n\n\n\n\nDeriving the Kelvin Wake Pattern\n\n\n\n\n\n\n\nPhysics\n\n\n\n\nWhen objects move at a constant speed through deep water, the intricate wave pattern can be derived by noticing that only waves stationary relative to the object persist.\n\n\n\n\n\n\nMay 24, 2020\n\n\nZiyue Li\n\n\n\n\n\n\n  \n\n\n\n\nHow to Write the setup.py File for Python Packages\n\n\n\n\n\n\n\nProgramming\n\n\n\n\nAn example and explanation of some minimum things to configure in the setup.py\n\n\n\n\n\n\nSep 22, 2019\n\n\nZiyue Li\n\n\n\n\n\n\n  \n\n\n\n\nCosmological Perspective\n\n\n\n\n\n\n\nPhysics\n\n\n\n\nUnderstanding some basic yet counter-intuitive concepts in an expanding universe.\n\n\n\n\n\n\nAug 25, 2019\n\n\nZiyue Li\n\n\n\n\n\n\n  \n\n\n\n\nThree Simple Steps to Start Using CSS Grid Template\n\n\n\n\n\n\n\nProgramming\n\n\n\n\nStart using this today, and skip all the headaches of webpage layout\n\n\n\n\n\n\nJun 16, 2019\n\n\nZiyue Li\n\n\n\n\n\n\n  \n\n\n\n\nExport Jupyter Document With Optional Code Visibility\n\n\n\n\n\n\n\nData Science\n\n\n\n\nGenerate an HTML file with a button to toggle code whenever the Jupyter notebook is saved\n\n\n\n\n\n\nJan 7, 2019\n\n\nZiyue Li\n\n\n\n\n\n\n  \n\n\n\n\nHow I solved the world’s hardest logic puzzle\n\n\n\n\n\n\n\nInformation Science\n\n\n\n\nThe logical paths I took to tackle the world’s hardest logic puzzle\n\n\n\n\n\n\nJan 20, 2017\n\n\nZiyue Li\n\n\n\n\n\n\n  \n\n\n\n\nStudy Notes for D3.js - 7 Basic Concepts to Grasp\n\n\n\n\n\n\n\nData Science\n\n\n\n\nI summarize 7 basic concepts that I find very important to understand when learning D3.\n\n\n\n\n\n\nMay 2, 2016\n\n\nZiyue Li\n\n\n\n\n\n\n  \n\n\n\n\nBlack Hole Physics in Interstellar\n\n\n\n\n\n\n\nPhysics\n\n\n\n\nThe Science of Interstellar\n\n\n\n\n\n\nNov 22, 2014\n\n\nZiyue Li\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "TIL/2022/2022-11-30-access_data_in_python_libraries.html",
    "href": "TIL/2022/2022-11-30-access_data_in_python_libraries.html",
    "title": "Access Data in Installed Python Package",
    "section": "",
    "text": "For a python package structured as the following:\nsetup.py\nsrc/\n  mypkg/\n    __init__.py\n      module.py\n      data/\n        tables.csv\nwe can include the data in the package by\nsetup(...,\n      packages=['mypkg'],\n      package_dir={'mypkg': 'src/mypkg'},\n      package_data={'mypkg': ['data/*']},\n     )\nin setup.py.\nIf we need to access the data files in other parts of this package, we can do\nimport pkg_resources\n\nDATA_PATH = pkg_resources.resource_filename('mypkg', 'data/')\nTABLE_PATH = pkg_resources.resource_filename('mypkg', 'data/tables.csv')\nThis makes sure to get the path to the data included in the package after installation."
  },
  {
    "objectID": "TIL/2022/2022-12-15-Fixing_the_Unable_to_Resolve_Your_Shell_Environment_Problem_in_VSCode.html",
    "href": "TIL/2022/2022-12-15-Fixing_the_Unable_to_Resolve_Your_Shell_Environment_Problem_in_VSCode.html",
    "title": "Fixing the “Unable to Resolve Your Shell Environment” Problem in VSCode",
    "section": "",
    "text": "You’ve probably come across this notification in VSCode:\n\n\n\n\n\nIt means that the shell environment defined in your .bashrc or .zshrc files is not resolved in a short amount of time. See detailed explanation here.\nUnfortunately, VSCode does not have an option to customize or disable that time limit. So to make it work, we need to remove some lines that are taking long from our .zshrc for VSCode.\nHere’s a simple example of not sourcing oh-my-zsh.sh when using VSCode:\n# In .zshrc\nif [[ \"${TERM_PROGRAM}\" != \"vscode\" ]]; then\n  plugins=(git zsh-autosuggestions zsh-syntax-highlighting)\n  source $ZSH/oh-my-zsh.sh\nfi\nIf you need to add this if statement at multiple places, you may want to simply create a separate .zshrc-vscode file and source that when using VSCode:\n# In .zshrc\nif [[ \"${TERM_PROGRAM}\" = \"vscode\" ]]; then\n    source ~/.zshrc-vscode\nelse\n    source ~/.zshrc-g\nfi"
  },
  {
    "objectID": "TIL/2022/2022-12-06-replace_certain_lines_in_file.html",
    "href": "TIL/2022/2022-12-06-replace_certain_lines_in_file.html",
    "title": "Replace Certain Lines in a Script Using Fileinput",
    "section": "",
    "text": "If we are using a script written by someone else, and we want to modify certain lines of it before execution, we can use Python’s fileinput module:\nimport sys\nimport fileinput\n\nwith fileinput.input('test.py', \n                     backup='.bak', # the file is moved to a backup file  \n                     inplace=True   # and standard output is directed to the input file\n                     ) as f:\n    for line in f:\n        if line.strip().startswith('print'):\n            line = f'print(\"This is a new message\")'            \n        # lines that are written to stdout will be written to the file\n        sys.stdout.write(line)\nWhen inplace=True, as in the above code, whatever’s written to stdout, will be written to the file. You can also specify a backup file, as we did in the example."
  },
  {
    "objectID": "TIL/2022/2022-11-23-aws-private_subnet_setup.html",
    "href": "TIL/2022/2022-11-23-aws-private_subnet_setup.html",
    "title": "Access Internet from Private Subnet in VPC",
    "section": "",
    "text": "I’m finally forced to learn the network configuration stuff in AWS VPC. The thing that was confusing me was the NAT Gateway.\nFor a private subnet to access the internet, we route traffic from the private subnet through a NAT Gateway which keeps out all traffic initiated from the internet. This gateway needs to be in a public subnet, so that it can access the internet through the Internet Gateway.\nTo route the traffic in this way, we need to make sure there’s an entry in the route table for the public subnet to connect to the Internet Gateway, and there’s an entry in the route table for the private subnet to connect to the NAT Gateway.\n\nStep 1: Create VPC, Public and Private Subnets\nCreate public and private subnets for each availability zone. Make sure that the subnets don’t overlap. For an explanation of subnets and CIDR notations:\n\nStep 2: Create Internet Gateway and NAT Gateway\nMake sure to create the NAT Gateway for each availability zone, and make sure they are created in the public subnets, select “public” connectivity type, and allocate an elastic IP Address.\nStep 3: Create Route Tables\nFor each public subnet, create a route table, add an entry to connect to the internet gateway, and associate it to that subnet.\nFor each private subnet, create a route table, add an entry to connect to the NAT Gateway in the same availability zone, and associate it to that private subnet.\nStep 4: Add access to AWS resources\nIf we want the subnets to have access to AWS services such as S3, we can create an endpoint for AWS services, and associate that endpoint to the route tables we created above.\nStep 5: Make Sure Network ACL and Security Groups Don’t Block the Internet Traffic\nWhen selecting security groups to use for services launched in the private subnet, make sure it allows traffic from and to the NAT Gateway.\nI was tripped up by this when setting up network connections for EMR Serverless."
  },
  {
    "objectID": "TIL/2022/2022-11-15-fastai-show_training_loop.html",
    "href": "TIL/2022/2022-11-15-fastai-show_training_loop.html",
    "title": "Show the Training Loop and CallBacks",
    "section": "",
    "text": "from fastai.test_utils import synth_learner\n\nlearn = synth_learner()\nlearn.show_training_loop()\n\nStart Fit\n   - before_fit     : [TrainEvalCallback, Recorder, ProgressCallback]\n  Start Epoch Loop\n     - before_epoch   : [Recorder, ProgressCallback]\n    Start Train\n       - before_train   : [TrainEvalCallback, Recorder, ProgressCallback]\n      Start Batch Loop\n         - before_batch   : [CastToTensor]\n         - after_pred     : []\n         - after_loss     : []\n         - before_backward: []\n         - before_step    : []\n         - after_step     : []\n         - after_cancel_batch: []\n         - after_batch    : [TrainEvalCallback, Recorder, ProgressCallback]\n      End Batch Loop\n    End Train\n     - after_cancel_train: [Recorder]\n     - after_train    : [Recorder, ProgressCallback]\n    Start Valid\n       - before_validate: [TrainEvalCallback, Recorder, ProgressCallback]\n      Start Batch Loop\n         - **CBs same as train batch**: []\n      End Batch Loop\n    End Valid\n     - after_cancel_validate: [Recorder]\n     - after_validate : [Recorder, ProgressCallback]\n  End Epoch Loop\n   - after_cancel_epoch: []\n   - after_epoch    : [Recorder]\nEnd Fit\n - after_cancel_fit: []\n - after_fit      : [ProgressCallback]"
  },
  {
    "objectID": "TIL/2023/2023-04-02-variable_shadows_function.html",
    "href": "TIL/2023/2023-04-02-variable_shadows_function.html",
    "title": "Subtle Bug: Variable Shadows Function",
    "section": "",
    "text": "Here’s an example:\n\ndef func(): pass\n\ndef func2(): pass\n\ndef test(x):\n    if x &gt;0:\n        func = func2\n    return func\n\n\ntest(0)\n\nUnboundLocalError: cannot access local variable 'func' where it is not associated with a value\n\n\nIn the function test, func is a new variable that gets assigned func2 if x is positive. It shadows the function func defined outside of the test function. So when x=0, the func is treated as a variable which is not defined, and the function func is not called.\nfunc does not fall back to the function func defined outside of the test function.\nThis is a subtle bug that can be hard to find.\nWe need to remember that if the same name is used for a variable inside the function, we have to continue to treat it as a variable in the function, even if it’s inside a branched if statement.\nTo fix this, we can either directly return the function func or func2 in the test function, or we can use a different name for the variable.\n\ndef func(): pass\n\ndef func2(): pass\n\ndef test(x):\n    if x &gt;0:\n        return func2\n    else:\n        return func\n\n\ntest(0)\n\n&lt;function __main__.func()&gt;\n\n\n\n\ndef func(): pass\n\ndef func2(): pass\n\ndef test(x):\n    if x &gt;0:\n        f =  func2\n    else:\n        f = func\n    return f\n\n\ntest(0)\n\n&lt;function __main__.func()&gt;"
  },
  {
    "objectID": "TIL/2023/2023-01-03-()_in_bash_vs_in_zsh.html",
    "href": "TIL/2023/2023-01-03-()_in_bash_vs_in_zsh.html",
    "title": "$() Command Substitution in Bash vs in Zsh",
    "section": "",
    "text": "A simple learning today: when using $() in Bash, it concatenates the outputs into one single line, while in Zsh, it does not seem to do so.\nIn bash\nfiles=$(ls)\necho $files\noutputs something like\nfile1.md file2.md file3.md\nBut when the same commands are executed in Zsh, I got\nfile1.md\nfile2.md\nfile3.md\nwith the line breaks preserved."
  },
  {
    "objectID": "ai_art-sd.html",
    "href": "ai_art-sd.html",
    "title": "Stable Diffusion",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nCyberpunk Knight\n\n\nFuturistic Retro Punk\n\n\n\n\n\n\nMay 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtwork Generation and Touchups Practice\n\n\nUsing ControlNet for generation and in-painting to tweak and fix the artwork to get the desired output.\n\n\n\n\n\n\nMar 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear of the Rabbit\n\n\nThe year of the tiger ends and the year of the rabbit begins.\n\n\n\n\n\n\nJan 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis Fleeting Life\n\n\nThis fleeting life will eventually be lost to us all. You might as well be bold and love someone, climb a mountain, and chase a dream.\n\n\n\n\n\n\nDec 31, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChristmas Gift\n\n\nI don’t want a single gift, ’cause I’ve got everything I need.\n\n\n\n\n\n\nDec 25, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHorse\n\n\nBGM:《马》by 福禄寿.\n\n\n\n\n\n\nDec 1, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Projects/2023-09-04-PikaQ.html",
    "href": "Projects/2023-09-04-PikaQ.html",
    "title": "pikaQ - A SQL Query Builder for Different Dialects",
    "section": "",
    "text": "Programmatically generate SQL queries for different dialects.\n\nThis library is heavily inspired by PyPika, so a lot of the syntax is based on how PyPika works. Just like PyPika, PikaQ replaces handwritten SQL queries with programmatic construction of queries. The main difference is that pikaQ is designed to generate different SQL dialects from the same code. This is done by using a common syntax that is then translated to the specific dialect.\nThis library provides the core components and implementation for constructing the Select query and the core mechanism for delayed translation into different dialects. It does not offer complete coverage of SQL syntax nor the detailed implementation of all the dialects. However, it should be easy to extend the library to support more SQL syntax and other types of queries you want to construct.\nValidation of SQL correctness is not an explicit goal of PikaQ. You are encouraged to check inputs you provide to PyPika or appropriately handle errors raised from your SQL database - just as you would have if you were writing SQL yourself.\n\n\npip install pikaQ\n\n\n\nThe translation of the query is delayed until the get_sql method is called. All the components of the query have an execute method that returns the SQL string for that component, and when get_sql is called, the execute method of all the components are called recursively to generate the final SQL string.\nFor example, if we want to write the same query in Spark SQL and AWS Athena, we might encounter this problem: we have ADD_MONTHS function in Spark SQL, but in AWS Athena (Presto) we don’t have this function. We can define an ADD_MONTHS function in the following way:\n\nfrom pikaQ.terms import custom_func\nfrom pikaQ.queries import Query\n\n\n@custom_func\ndef add_months(column, value, dialect='spark'):\n    if dialect == 'athena':\n        return f\"DATE_ADD('month', {value}, {column})\"\n    elif dialect == 'spark':\n        return f'ADD_MONTH({column}, {value})'\n    else:\n        raise ValueError(f'Unsupported dialect: {dialect}')\n\n\nq = (Query.from_('table')\n        .select('col1', add_months('col2', 3).as_('col2'))\n)\n\nThen we can generate the query for Spark SQL and AWS Athena:\n\nprint(q.get_sql(dialect='athena'))\n\nselect col1, DATE_ADD('month', 3, col2) AS col2\nfrom table\n\n\n\nprint(q.get_sql(dialect='spark'))\n\nselect col1, ADD_MONTH(col2, 3) AS col2\nfrom table\n\n\n\n\n\nA more complex example to show how the syntax works:\n\nfrom pikaQ.queries import Query, Table, Field, AliasedQuery\nfrom pikaQ.terms import Case, Preceding, CURRENT_ROW\nimport pikaQ.functions as fn\n\n\na = Table('tbl1').as_('a')\nb = Table('tbl2').as_('b')\ns = AliasedQuery('s')\nm = AliasedQuery('m')\nv = AliasedQuery('v')\n\nq0 = (Query\n      .from_(a)\n      .select(\n         a.col1,\n         a.col2,\n         fn.Sum(a.col3).over(b.col2).rows(Preceding(3), CURRENT_ROW).as_('total'), \n         fn.RowNumber().over(b.col2).orderby(b.col4).as_('row_num')\n      ).distinct()\n      .where((Field('col2')-100&gt;2) & (Field('col3')/9&lt;=1))\n      .orderby(b.col2)\n)\nq1 = (Query\n      .from_(b)\n      .select(b.col1, b.col2, fn.Avg(b.col3).as_('avg'))\n      .groupby(b.col1, b.col2)\n      .having(fn.Count(b.col3)&gt;2)\n)\n\nq = (Query\n     .with_(q0, 's')\n     .with_(Query\n         .from_(s)\n         .select(s.star())\n         .where(s.row_num == 1), 'm')\n     .with_(q1, 'v')\n     .from_('v')\n     .join('m')\n        .on(\n            (v.col1 == m.col1) &\n            (v.col2 == m.col2)\n            )\n     .select(\n         v.col1, v.col2, v.avg,\n         Case().when(m.total&gt;100, 1).else_(0).as_('flag')\n         )\n)\n\nprint(q.get_sql())\n\nwith s as (\nselect distinct a.col1, a.col2, SUM(a.col3) OVER (PARTITION BY b.col2 ROWS BETWEEN 3 PRECEDING AND CURRENT_ROW) AS total, ROW_NUMBER() OVER (PARTITION BY b.col2 ORDER BY b.col4) AS row_num\nfrom tbl1 as a\nwhere col2 - 100 &gt; 2 and col3 / 9 &lt;= 1\norder by b.col2)\n\n, m as (\nselect s.*\nfrom s\nwhere s.row_num = 1)\n\n, v as (\nselect b.col1, b.col2, AVG(b.col3)\nfrom tbl2 as b\ngroup by b.col1, b.col2\nhaving COUNT(b.col3) &gt; 2)\n\nselect v.col1, v.col2, v.avg, CASE\nWHEN m.total &gt; 100 THEN 1\nELSE 0\nEND AS flag\nfrom v\njoin m on v.col1 = m.col1 and v.col2 = m.col2\n\n\nFor more syntax examples, please refer to the docs.\n\n\n\nOne can use the core components and logic implemented in this library to extend the functionality to support more SQL syntax and other types of queries. For details of how to extend the SelectQuery to support more clauses, please refer to the Extending Query section of the docs."
  },
  {
    "objectID": "Projects/2023-09-04-PikaQ.html#install",
    "href": "Projects/2023-09-04-PikaQ.html#install",
    "title": "pikaQ - A SQL Query Builder for Different Dialects",
    "section": "",
    "text": "pip install pikaQ"
  },
  {
    "objectID": "Projects/2023-09-04-PikaQ.html#delayed-translation",
    "href": "Projects/2023-09-04-PikaQ.html#delayed-translation",
    "title": "pikaQ - A SQL Query Builder for Different Dialects",
    "section": "",
    "text": "The translation of the query is delayed until the get_sql method is called. All the components of the query have an execute method that returns the SQL string for that component, and when get_sql is called, the execute method of all the components are called recursively to generate the final SQL string.\nFor example, if we want to write the same query in Spark SQL and AWS Athena, we might encounter this problem: we have ADD_MONTHS function in Spark SQL, but in AWS Athena (Presto) we don’t have this function. We can define an ADD_MONTHS function in the following way:\n\nfrom pikaQ.terms import custom_func\nfrom pikaQ.queries import Query\n\n\n@custom_func\ndef add_months(column, value, dialect='spark'):\n    if dialect == 'athena':\n        return f\"DATE_ADD('month', {value}, {column})\"\n    elif dialect == 'spark':\n        return f'ADD_MONTH({column}, {value})'\n    else:\n        raise ValueError(f'Unsupported dialect: {dialect}')\n\n\nq = (Query.from_('table')\n        .select('col1', add_months('col2', 3).as_('col2'))\n)\n\nThen we can generate the query for Spark SQL and AWS Athena:\n\nprint(q.get_sql(dialect='athena'))\n\nselect col1, DATE_ADD('month', 3, col2) AS col2\nfrom table\n\n\n\nprint(q.get_sql(dialect='spark'))\n\nselect col1, ADD_MONTH(col2, 3) AS col2\nfrom table"
  },
  {
    "objectID": "Projects/2023-09-04-PikaQ.html#select-query",
    "href": "Projects/2023-09-04-PikaQ.html#select-query",
    "title": "pikaQ - A SQL Query Builder for Different Dialects",
    "section": "",
    "text": "A more complex example to show how the syntax works:\n\nfrom pikaQ.queries import Query, Table, Field, AliasedQuery\nfrom pikaQ.terms import Case, Preceding, CURRENT_ROW\nimport pikaQ.functions as fn\n\n\na = Table('tbl1').as_('a')\nb = Table('tbl2').as_('b')\ns = AliasedQuery('s')\nm = AliasedQuery('m')\nv = AliasedQuery('v')\n\nq0 = (Query\n      .from_(a)\n      .select(\n         a.col1,\n         a.col2,\n         fn.Sum(a.col3).over(b.col2).rows(Preceding(3), CURRENT_ROW).as_('total'), \n         fn.RowNumber().over(b.col2).orderby(b.col4).as_('row_num')\n      ).distinct()\n      .where((Field('col2')-100&gt;2) & (Field('col3')/9&lt;=1))\n      .orderby(b.col2)\n)\nq1 = (Query\n      .from_(b)\n      .select(b.col1, b.col2, fn.Avg(b.col3).as_('avg'))\n      .groupby(b.col1, b.col2)\n      .having(fn.Count(b.col3)&gt;2)\n)\n\nq = (Query\n     .with_(q0, 's')\n     .with_(Query\n         .from_(s)\n         .select(s.star())\n         .where(s.row_num == 1), 'm')\n     .with_(q1, 'v')\n     .from_('v')\n     .join('m')\n        .on(\n            (v.col1 == m.col1) &\n            (v.col2 == m.col2)\n            )\n     .select(\n         v.col1, v.col2, v.avg,\n         Case().when(m.total&gt;100, 1).else_(0).as_('flag')\n         )\n)\n\nprint(q.get_sql())\n\nwith s as (\nselect distinct a.col1, a.col2, SUM(a.col3) OVER (PARTITION BY b.col2 ROWS BETWEEN 3 PRECEDING AND CURRENT_ROW) AS total, ROW_NUMBER() OVER (PARTITION BY b.col2 ORDER BY b.col4) AS row_num\nfrom tbl1 as a\nwhere col2 - 100 &gt; 2 and col3 / 9 &lt;= 1\norder by b.col2)\n\n, m as (\nselect s.*\nfrom s\nwhere s.row_num = 1)\n\n, v as (\nselect b.col1, b.col2, AVG(b.col3)\nfrom tbl2 as b\ngroup by b.col1, b.col2\nhaving COUNT(b.col3) &gt; 2)\n\nselect v.col1, v.col2, v.avg, CASE\nWHEN m.total &gt; 100 THEN 1\nELSE 0\nEND AS flag\nfrom v\njoin m on v.col1 = m.col1 and v.col2 = m.col2\n\n\nFor more syntax examples, please refer to the docs."
  },
  {
    "objectID": "Projects/2023-09-04-PikaQ.html#extension",
    "href": "Projects/2023-09-04-PikaQ.html#extension",
    "title": "pikaQ - A SQL Query Builder for Different Dialects",
    "section": "",
    "text": "One can use the core components and logic implemented in this library to extend the functionality to support more SQL syntax and other types of queries. For details of how to extend the SelectQuery to support more clauses, please refer to the Extending Query section of the docs."
  },
  {
    "objectID": "Projects/2023-07-16-Latent_Upscale.html",
    "href": "Projects/2023-07-16-Latent_Upscale.html",
    "title": "Latent Upscale Plugin for Automatic1111 (Stable Diffusion)",
    "section": "",
    "text": "Enhance the latent upscale options in the img2img process in Automatic1111 to provide more flexibility and better image quality."
  },
  {
    "objectID": "Projects/2023-07-16-Latent_Upscale.html#motivation",
    "href": "Projects/2023-07-16-Latent_Upscale.html#motivation",
    "title": "Latent Upscale Plugin for Automatic1111 (Stable Diffusion)",
    "section": "Motivation",
    "text": "Motivation\n\nThe current img2img process lacks the ability to select the “Hires Fix” latent upscale options.\nThe default latent upscale method (“bilinear”) often produces blurry images.\n\nThis plugin introduces alternative interpolation methods for upscaling and offers different schedulers for the diffusion process, resulting in superior upscaled images. Moreover, this plugin expands the upscale options available in the Latent Space, surpassing those offered by the “Hires Fix” for the txt2img process."
  },
  {
    "objectID": "Projects/2023-07-16-Latent_Upscale.html#example-comparison",
    "href": "Projects/2023-07-16-Latent_Upscale.html#example-comparison",
    "title": "Latent Upscale Plugin for Automatic1111 (Stable Diffusion)",
    "section": "Example Comparison",
    "text": "Example Comparison\nOriginal Image:\n\nThe default latent upscale (choose Resize mode “latent upscale”): \nLatent Upscale Plugin (Upscale method: “nearest-exact”, Scheduler: “simple”)"
  },
  {
    "objectID": "Projects/2023-07-16-Latent_Upscale.html#installation",
    "href": "Projects/2023-07-16-Latent_Upscale.html#installation",
    "title": "Latent Upscale Plugin for Automatic1111 (Stable Diffusion)",
    "section": "Installation",
    "text": "Installation\n\nYou can find the “Latent Upscale” plugin in the Available section under the Extensions tab in the WebUI. Simply search for “Latent Upscale” in the extension search bar to locate it and click on “install”.\nDon’t forget to go back to Installed and click on Apply."
  },
  {
    "objectID": "Projects/2023-07-16-Latent_Upscale.html#usage",
    "href": "Projects/2023-07-16-Latent_Upscale.html#usage",
    "title": "Latent Upscale Plugin for Automatic1111 (Stable Diffusion)",
    "section": "Usage",
    "text": "Usage\n\nAt the bottom of the img2img tab, you can select the newly installed Latent Upscale script in the Script dropdown menu.\nTo benefit from these enhancements, make sure you have the “Just resize (latent upscale)” option selected for Resize mode. Additionally, all the parameters present in the user interface remain applicable, alongside the new options provided by this plugin in “Upscale Method” and “Scheduler”."
  },
  {
    "objectID": "Projects/2023-07-16-Latent_Upscale.html#tips",
    "href": "Projects/2023-07-16-Latent_Upscale.html#tips",
    "title": "Latent Upscale Plugin for Automatic1111 (Stable Diffusion)",
    "section": "Tips",
    "text": "Tips\n\nOpting for “nearest”, “nearest-exact”, or “area” in the Upscale Method and “simple” or “normal” in the Scheduler can often lead to crisper images. However, don’t hesitate to experiment with different choices to discover the best outcome.\nIf you want more details in the image, you can try to increase the number of steps in the diffusion process. However, this will also increase the time required to generate the image."
  },
  {
    "objectID": "Projects/2023-07-16-Latent_Upscale.html#how-this-came-about",
    "href": "Projects/2023-07-16-Latent_Upscale.html#how-this-came-about",
    "title": "Latent Upscale Plugin for Automatic1111 (Stable Diffusion)",
    "section": "How this came about",
    "text": "How this came about\nThis all started when I noticed that the default “Just resize (latent upscale)” mode in Automatic1111 produces foggy images, but when I played with latent upscale in Comfyui, the results are much sharper.\nI wanted to figure out why.\n\nHow Latent Upscale Works:\nThe original image is first encoded into the latent space, which is upscaled by the correct factor before fed into the diffusion (de-noising) process, and then decoded to the upscaled image.\n\n\nI found 2 problems in Automatic1111’s implementation:\n\nIt uses the “bilinear” method, which often results in blurry upscaled images. It does not provide users with other options to choose from.\nThe number of steps users set was applied to the full scheduler, effectively reducing the steps for “de-noising”. For example, if the user sets the steps to be “30” and the de-noise strength is set to 0.4, the diffusion process will only run for 30*0.4 = 12 steps."
  },
  {
    "objectID": "Projects/2023-07-16-Latent_Upscale.html#solutions",
    "href": "Projects/2023-07-16-Latent_Upscale.html#solutions",
    "title": "Latent Upscale Plugin for Automatic1111 (Stable Diffusion)",
    "section": "Solutions",
    "text": "Solutions\n\nFor problem 1, I simply replaced this line of code. Instead of hard coding the interpolation method, I allowed the users to choose their own method.\n\n\n\nI turned on a fix that’s already in the code base but for some reason not applied by default:\n\n  opts.img2img_fix_steps = True\nso the de-noising process has the correct number of steps."
  },
  {
    "objectID": "Projects/2023-07-16-Latent_Upscale.html#technical-details",
    "href": "Projects/2023-07-16-Latent_Upscale.html#technical-details",
    "title": "Latent Upscale Plugin for Automatic1111 (Stable Diffusion)",
    "section": "Technical Details",
    "text": "Technical Details\n\nThis plugin overrides the default init method for StableDiffusionProcessingImg2Img to include additional features:\n\nIt adds the option to choose the “Upscale Method” interpolation method when creating the latent image.\nIt ensures that the diffusion process runs for the correct number of steps, as specified by the user, by setting opts.img2img_fix_steps = True. It is unclear why this was not the default setting for img2img.\n\nThis plugin assigns the sampler_noise_scheduler_override method for StableDiffusionProcessingImg2Img so that our custom schedulers can be used for the diffusion process."
  },
  {
    "objectID": "Projects/2022-11-21-Nbdev_ignore.html#what-this-is",
    "href": "Projects/2022-11-21-Nbdev_ignore.html#what-this-is",
    "title": "Nbdev_ignore",
    "section": "What this is",
    "text": "What this is\nWhen using the nbdev library, I often find myself having to write\n#| hide\n#| eval: false\n...\nin order for that cell in Jupyter Notebook to be ignored by both the tests and docs. It would great to have a simple directive to do this, and this is the ignore directive:\n#| ignore\n...\nIt’s equivalent to the above directives."
  },
  {
    "objectID": "Projects/2022-11-21-Nbdev_ignore.html#installation",
    "href": "Projects/2022-11-21-Nbdev_ignore.html#installation",
    "title": "Nbdev_ignore",
    "section": "Installation",
    "text": "Installation\npip install nbdev_ignore"
  },
  {
    "objectID": "Projects/2022-11-21-Nbdev_ignore.html#how-to-use",
    "href": "Projects/2022-11-21-Nbdev_ignore.html#how-to-use",
    "title": "Nbdev_ignore",
    "section": "How to use",
    "text": "How to use\nTo enable the #| ignore directive, in your settings.ini make sure to:\n\nAdd nbdev_ignore as a requirement\nAdd procs = nbdev_igore.core:ignore_, where it should point to the exact function being called\nAdd it to test flags: tst_flags = ignore, so that cells with this directive also avoids testing. If you already have other test flags, separate them with space. For example, if you already have notest as your test flag, then tst_flags = notest ignore."
  },
  {
    "objectID": "Projects/2022-11-21-Nbdev_ignore.html#how-it-works",
    "href": "Projects/2022-11-21-Nbdev_ignore.html#how-it-works",
    "title": "Nbdev_ignore",
    "section": "How it works",
    "text": "How it works\nThere’s only one function ignore_ in this module. It’s exactly the same as the hide_ processor in nbdev, so that “#| ignore” serves the same purpose as “#| hide”. For details on how it works, see here.\nIn order for it to also serve as a test flag, we will need to manually add it to tst_flags (see below) so tests will ignore cells with this directive. Currently there’s no simple way to hack the nbdev_test process, so this has to be done manually."
  },
  {
    "objectID": "Projects/2022-11-21-Nbdev_ignore.html#result",
    "href": "Projects/2022-11-21-Nbdev_ignore.html#result",
    "title": "Nbdev_ignore",
    "section": "Result",
    "text": "Result\nWe can now write #|ignore for the cell to be ignored by both tests and docs, but still kept in the notebook:\n#|ignore\n\nfrom pyspark.sql import SparkSession\nfrom mock import patch\n\nspark = (SparkSession.builder\n        .config(\"fs.s3a.aws.credentials.provider\",\n                \"com.amazonaws.auth.profile.ProfileCredentialsProvider\")\n        .appName(\"app_name\")\n        .getOrCreate()\n        )\n\ncolumns = [\"address\", \"date\"]\ndata = [(\"address1\", \"20211001\")]\ndf = spark.createDataFrame(data).toDF(*columns)\n\n@patch(\"pyspark.sql.session.DataFrameReader.load\", return_value = df)\ndef test(spark_load_mock):\n    df = fake_func(spark)\n    return df\n\ndfpd = test()"
  },
  {
    "objectID": "AI_art/stable_diffusion/horse.html",
    "href": "AI_art/stable_diffusion/horse.html",
    "title": "Horse",
    "section": "",
    "text": "《马》by 福禄寿."
  },
  {
    "objectID": "AI_art/stable_diffusion/this_fleeting_life.html",
    "href": "AI_art/stable_diffusion/this_fleeting_life.html",
    "title": "This Fleeting Life",
    "section": "",
    "text": "After multiple tries, I was able to create this aging animation using Deforum and a fine-tuned Stable Diffusion model.\nThis fleeting life will eventually be lost to us all. You might as well be bold and love someone, climb a mountain, and chase a dream."
  },
  {
    "objectID": "AI_art/stable_diffusion/Christmas_gift.html",
    "href": "AI_art/stable_diffusion/Christmas_gift.html",
    "title": "Christmas Gift",
    "section": "",
    "text": "The song is Christmas List by Anson Seabra, covered by Suho陈仕雨."
  },
  {
    "objectID": "AI_art/stable_diffusion/happy_the_year_of_the_rabbit.html",
    "href": "AI_art/stable_diffusion/happy_the_year_of_the_rabbit.html",
    "title": "Year of the Rabbit",
    "section": "",
    "text": "The year of the tiger ends and the year of the rabbit begins. This animation is made using Deforum and a fine-tuned Stable Diffusion model."
  },
  {
    "objectID": "Projects/2022-10-01-DreamBooth.html#train-on-stable-diffusion-v1.4",
    "href": "Projects/2022-10-01-DreamBooth.html#train-on-stable-diffusion-v1.4",
    "title": "DreamBooth",
    "section": "Train on Stable Diffusion V1.4",
    "text": "Train on Stable Diffusion V1.4\nI adapted a Google Colab Notebook to fine-tune the stability diffusion model with DreamBooth, and added sections to save the trained model directly to HuggingFace, so it can be pulled from the hub in the future.\nThe following are some profile artworks generated by a model trained with photos of my face. The results are pretty interesting. Some of them do have some resemblance with me, while others do not look that much like me."
  },
  {
    "objectID": "Projects/2022-10-01-DreamBooth.html#train-on-the-arcane-diffusion",
    "href": "Projects/2022-10-01-DreamBooth.html#train-on-the-arcane-diffusion",
    "title": "DreamBooth",
    "section": "Train on the Arcane Diffusion",
    "text": "Train on the Arcane Diffusion\nWe can also train on fined-tuned stability models. I fine-tuned the Arcane Diffusion Model on photos of me using the same DreamBooth Notebook.\nThe Arcane style got preserved, and now I can generate pictures of “me” in this style:"
  },
  {
    "objectID": "Projects/2022-11-09-Whisper2Subtitles.html",
    "href": "Projects/2022-11-09-Whisper2Subtitles.html",
    "title": "Whisper2Subtitles",
    "section": "",
    "text": "A simple Google Colab Notebook to generate transcribed subtitles for videos/audios using OpenAI’s open source whisper model, with options to generate translated subtitles.\nYou can choose to generate translations using Facebooks’ M2M100_418 model model or manually add translated texts from other tools. The original texts and translated texts will be combined into one bilingual subtitle.\nThere’s also an option to burn the subtitle into video using ffmpeg directly in the notebook."
  },
  {
    "objectID": "Projects/2022-11-25-Code_Insertion.html#what-this-is",
    "href": "Projects/2022-11-25-Code_Insertion.html#what-this-is",
    "title": "Code-Insertion",
    "section": "What this is",
    "text": "What this is\nI was looking for a way to add share buttons at the bottom of each post before the comment section (see for details). I searched through the Quarto documentation, and couldn’t find a viable solution, so I created this extension to enable code insertion immediately before and/or after a post/page.\n\nWhen you insert code before the post, it will be after the post header (section that contains author and date).\nWhen you insert code after the post, it will be before the comment section."
  },
  {
    "objectID": "Projects/2022-11-25-Code_Insertion.html#installing",
    "href": "Projects/2022-11-25-Code_Insertion.html#installing",
    "title": "Code-Insertion",
    "section": "Installing",
    "text": "Installing\nquarto add feynlee/code-insertion\nThis will install the extension under the _extensions subdirectory. If you’re using version control, you will want to check in this directory for your Quarto website."
  },
  {
    "objectID": "Projects/2022-11-25-Code_Insertion.html#using",
    "href": "Projects/2022-11-25-Code_Insertion.html#using",
    "title": "Code-Insertion",
    "section": "Using",
    "text": "Using\nIn the front matter of a post, the code-insertion filter and add insert-before-post and/or insert-after-post parameters that point to a markdown file with sections you want to insert before and/or after the post.\nfilters:\n  - code-insertion\ninsert-before-post: before_post.md\ninsert-after-post: after_post.md\nYou need to specify the path to the markdown file that contains the code you want to insert into your post. Currently this extension does not support inline code insertion (i.e. specifying the code to be inserted right within YAML front matter).\nTip: You can add this to _metadata.yml under the folder containing all your posts, so that all of them can share this setting."
  },
  {
    "objectID": "Projects/2022-11-25-Code_Insertion.html#example",
    "href": "Projects/2022-11-25-Code_Insertion.html#example",
    "title": "Code-Insertion",
    "section": "Example",
    "text": "Example\nWith this extension, I was finally able to add the social share buttons."
  },
  {
    "objectID": "Projects/2021-12-15-Learning_Blender.html",
    "href": "Projects/2021-12-15-Learning_Blender.html",
    "title": "Learning Blender",
    "section": "",
    "text": "Some projects I did while learning Blender."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\npikaQ - A SQL Query Builder for Different Dialects\n\n\n\nTools\n\n\n\nWrite it once, and automatically generate SQL queries for different database platforms.\n\n\n\n\n\n\nSep 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLatent Upscale Plugin for Automatic1111 (Stable Diffusion)\n\n\n\nTools\n\n\n\nThis plugin provides better options for latent upscale in img2img, surpassing those offered by “Hires Fix” for the txt2img process..\n\n\n\n\n\n\nJul 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode-Insertion\n\n\n\nTools\n\n\n\nA Quarto extension that enables code insertion immediately before and/or after a post/page.\n\n\n\n\n\n\nNov 25, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNbdev_ignore\n\n\n\nTools\n\n\n\nAdd a #|ignore directive to hide the cell and avoid execution during testing and docs generation when using nbdev for development.\n\n\n\n\n\n\nNov 21, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhisper2Subtitles\n\n\n\nDeep Learning\n\n\n\nAdd bilingual subtitles to videos using OpenAI’s Whisper model.\n\n\n\n\n\n\nNov 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDreamBooth\n\n\n\nDeep Learning\n\n\n\nFine-tuning Stable Diffusion to Generate Artwork with My Face.\n\n\n\n\n\n\nOct 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Blender\n\n\n\n3D\n\n\n\nSome 3D animation projects I did when learning Blender.\n\n\n\n\n\n\nDec 15, 2021\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "TIL/2023/2023-01-13-get_function_with_its_name.html",
    "href": "TIL/2023/2023-01-13-get_function_with_its_name.html",
    "title": "Get Function from Modules Using Its Name",
    "section": "",
    "text": "Sometimes we need to obtain a function defined in a certain module using its name. If the function you are calling is defined in the same module, we can use globals() or locals():\n\nglobals() returns a dictionary with the global symbol table:\nfunc = globals()[\"func_name\"]\nlocals() returns a dictionary with the current local symbol table:\nfunc = locals()[\"func_name\"]\n\n\ndef demo_func(*args, **kwargs):\n    pass\n\n\ndef test_locals(*args, **kwargs):\n    \"Test whether we can get the local functions using locals()\"\n    def local_demo_func(self, *args, **kwargs):\n        pass\n\n    return locals()['local_demo_func'] == local_demo_func\n\n\n# `globals()` returns a dictionary with the global symbol table:\nassert globals()['demo_func'] == demo_func\n# `locals()` returns a dictionary with the current local symbol table\nassert test_locals()\n\nIf it’s defined another module, we can simply do\nimport foo\n\nfunc = getattr(foo, 'demo_func')\nFor example:\n\nfrom datetime import date\n\nassert getattr(date, 'today') == date.today"
  },
  {
    "objectID": "TIL/2022/2022-12-04-set_function_as_methods.html",
    "href": "TIL/2022/2022-12-04-set_function_as_methods.html",
    "title": "How to Set Function as Methods",
    "section": "",
    "text": "TIL: In python, functions act as descriptors. When they are called from an instance, they get turned into “bound method”, which automatically inserts the instance into the function as its first argument: obj.f(*args) call is transformed into f(obj, *args). If they are called from a class, we get the function itself, and we need to provide all the arguments ourselves: Calling cls.f(*args) becomes f(*args).\nIn the following example, A.func() raises error because it expects one argument, while A().func() runs without a problem because A() is automatically inserted into the func.\n\nclass A:\n    def __init__(self):\n        pass\n\n    def func(self):\n        return 1\n\nA.func()\n\nTypeError: func() missing 1 required positional argument: 'self'\n\n\n\nA().func()\n\n1\n\n\nBecause this behavior is associated with functions (those defined with def) themselves, we don’t need to do anything different if we want to turn a function into a method. However we write them in the class definition, we can do the same thing here.\nAdditionally, we can use MethodType to return a method that automatically inserts the object’s class as the first argument, equivalent to using the classmethod decorator.\n\nfrom types import MethodType\n\nclass A:\n    x = 10\n\n    def __init__(self):\n        self.xx=100\n\ndef func(cls):\n    return cls.x + 1\n\ndef ins_func(self):\n    return self.xx + 1\n\n\n# Set a function as method\nsetattr(A, 'func', ins_func)\n# Set a function as classmethod\nsetattr(A, 'class_func1', MethodType(func, A))\nsetattr(A, 'class_func2', classmethod(func))\n# Set a function as property\nsetattr(A, 'property_func', property(ins_func))\n\n\nA.class_func1()\nA.class_func2()\nA().class_func1()\nA().class_func2()\n\n11\n\n\n11\n\n\n11\n\n\n11\n\n\n\na = A()\na.func\na.func()\n\n&lt;bound method ins_func of &lt;__main__.A object at 0x7f9f40b79b50&gt;&gt;\n\n\n101\n\n\n\na.property_func\n\n101"
  },
  {
    "objectID": "TIL/2022/2022-12-12-get_list_of_folders_of_updated_files_since_last_merge.html",
    "href": "TIL/2022/2022-12-12-get_list_of_folders_of_updated_files_since_last_merge.html",
    "title": "How to Get a List of Directories with Updated Files Since the Last Git Merge",
    "section": "",
    "text": "It’s as simple as the following:\nfolders=$(git diff --name-only HEAD@{1}..HEAD | awk -F/ '{print $1}' | uniq)\ngit diff gets all files that have changed, awk -F/ parses out the directory name before the first /, and finally uniq returns a list of unique directory names."
  },
  {
    "objectID": "TIL/2022/2022-11-16-fastai-store_attr_infinite_recursion.html",
    "href": "TIL/2022/2022-11-16-fastai-store_attr_infinite_recursion.html",
    "title": "Infinite Recursion When Using store_attr and Overwriting __getattr__",
    "section": "",
    "text": "from fastcore.basics import store_attr\n\nclass Table:\n    def __init__(self, name) -&gt; None:\n        store_attr()\n\n    def __getattr__(self, __name: str):\n        return f\"{self.name}.{__name}\"\n\n\nt = Table('tbl')\nt.column\n\nRecursionError: maximum recursion depth exceeded while calling a Python object\n\n\nIf we take a look at store_attr, we see that the problem occurs at the step where store_attr() calls hasattr(self, '__slots__'), which calls __getattr__ when __slots__ is not available. In fact, store_attr calls a few attributes that start with __.\n\ndef store_attr(names=None, self=None, but='', cast=False, store_args=None, **attrs):\n    \"Store params named in comma-separated `names` from calling context into attrs in `self`\"\n    fr = sys._getframe(1)\n    args = argnames(fr, True)\n    if self: args = ('self', *args)\n    else: self = fr.f_locals[args[0]]\n    if store_args is None: store_args = not hasattr(self,'__slots__')\n    if store_args and not hasattr(self, '__stored_args__'): self.__stored_args__ = {}\n    anno = annotations(self) if cast else {}\n    if names and isinstance(names,str): names = re.split(', *', names)\n    ns = names if names is not None else getattr(self, '__slots__', args[1:])\n    added = {n:fr.f_locals[n] for n in ns}\n    attrs = {**attrs, **added}\n    if isinstance(but,str): but = re.split(', *', but)\n    attrs = {k:v for k,v in attrs.items() if k not in but}\n    return _store_attr(self, anno, **attrs)\n\nTherefore, if we want to use store_attr(), when overwriting __getattr__, we need to protect those called by store_attr(), otherwise there will be an infinite loop.\n\nfrom fastcore.basics import store_attr\n\nclass Table:\n    def __init__(self, name) -&gt; None:\n        store_attr()\n\n    def __getattr__(self, __name: str):\n        if __name.startswith('__'):\n            return super().__getattr__(__name)\n        else:\n            return f\"{self.name}.{__name}\"\n\n\nt = Table('tbl')\nt.column\n\n'tbl.column'"
  },
  {
    "objectID": "TIL/2022/2022-12-28-f_string_in_python.html",
    "href": "TIL/2022/2022-12-28-f_string_in_python.html",
    "title": "Append and Prepend Characters in Python f-Strings",
    "section": "",
    "text": "text = \"Demo\"\nprint(f'{text:*&lt;10}')\nprint(f'{text:*&gt;10}')\nprint(f'{text:*^10}')\n\nDemo******\n******Demo\n***Demo***"
  },
  {
    "objectID": "TIL/2022/2022-11-06-pip_install_from_private_repo.html",
    "href": "TIL/2022/2022-11-06-pip_install_from_private_repo.html",
    "title": "Pip Install from a Private Repo",
    "section": "",
    "text": "You can pip install in the following way:\npip install &lt;package_name&gt;@git+ssh://git@github.com/&lt;user&gt;/&lt;repo_name&gt;@&lt;branch&gt;\nIn setup.py, we can add these packages in the following way:\nsetup(\n  name='&lt;package&gt;',\n  install_requires=[\n    '&lt;package_name&gt;@git+ssh://git@github.com/&lt;user&gt;/&lt;repo_name&gt;@&lt;branch&gt;',\n    '&lt;package_name&gt;@git+https://&lt;access_token&gt;@github.com/&lt;user&gt;/&lt;repo_name&gt;@&lt;branch&gt;'\n  ]\n)\nIf we are doing editable installation, it looks like the following:\npip install -e https://&lt;access_token&gt;@github.com/&lt;user&gt;/&lt;repo_name&gt;#egg=&lt;package_name&gt;\nFor GitLab CI/CD, one needs to do it in the following way:\npip install -e https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.example.com/&lt;namespace&gt;/&lt;project&gt;#egg=&lt;package_name&gt;"
  },
  {
    "objectID": "books/books.html",
    "href": "books/books.html",
    "title": "Books",
    "section": "",
    "text": "goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                The Alignment Problem\n              \n                \n                  Machine Learning and Human Values\n                \n              \n              How we try to get machines to do what we want and what we have learned about ourselves in the process.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Project Hail Mary\n              \n              \n              The less you know the better. If you love The Martian, you need to read this one.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Hidden Spring\n              \n                \n                  A Journey to the Source of Consciousness\n                \n              \n              The source of consciousness may be the brainy stem instead of the cortex.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                The Order of Time\n              \n              \n              A great survey of our current understandings of how time behaves and some extremely thought provoking cutting edge research and theories about the nature of “time”.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Being Mortal\n              \n                \n                  Medicine and What Matters in the End\n                \n              \n              Educational and thought-provoking. I can't recommend this enough to anyone that's mortal. There are hard facts about our life near the end, and we all need to learn how to live and how to die.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Liquid Rules\n              \n                \n                  The Delightful & Dangerous Substances that Flow Through Our Lives\n                \n              \n              Set over the course of a flight from London to San Francisco, Liquid Rules offers readers a fascinating and informative tour of these formless substances we encounter in our daily lives.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Naked Money\n              \n                \n                  A Revealing Look at What It Is and Why It Matters\n                \n              \n              An easy-to-digest overview of many interesting concepts around the nature of money.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Rising Out of Hatred\n              \n                \n                  The Awakening of a Former White Nationalist\n                \n              \n              The gripping journey of how Derek Black, the heir apparent to the White Supremacist throne, grew out the indoctronated worldview through contact with the diverse community at college.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Human Errors\n              \n                \n                  A Panorama of Our Glitches, from Pointless Bones to Broken Genes\n                \n              \n              An illuminating, entertaining tour of the biological, physical, genetic, behavior imperfections that make us human.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                How to Change Your Mind\n              \n                \n                  What the New Science of Psychedelics Teaches Us About Consciousness, Dying, Addiction, Depression, and Transcendence\n                \n              \n              An interesting and thought-provoking journey to understand how psychedelic drugs change our worldview and what human consciousness can be.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Deep\n              \n                \n                  Freediving, Renegade Science, and What the Ocean Tells Us about Ourselves\n                \n              \n              So many fascinating stories and a great introduction to the ocean.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Close Encounters with Humankind\n              \n                \n                  A Paleoanthropologist Investigates Our Evolving Species\n                \n              \n              A very readable intro to paleoanthropology\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                The Rise and Fall of the Dinosaurs\n              \n                \n                  The Untold Story of a Lost World\n                \n              \n              Accounts of some of the remarkable discoveries that piece together the story of dinosaurs\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Born a Crime\n              \n                \n                  Stories From a South African Childhood\n                \n              \n              Surprisingly funny, informative and gives you a new perspective on things\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Creativity, Inc.\n              \n                \n                  Overcoming the Unseen Forces That Stand in the Way of True Inspiration\n                \n              \n              Some of the best answers to the question: \"what does it mean to manage well?\"\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                A Higher Loyalty\n              \n                \n                  Truth, Lies, and Leadership\n                \n              \n              In a very personal manner, the author lays out his thinking behind some of the hardest decisions in his career.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                The Martian\n              \n              \n              One of the very few true hard sci-fi books nowadays, filled with great techincal goodreads.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Stuff Matters\n              \n                \n                  Exploring the Marvelous Materials That Shape Our Man-Made World\n                \n              \n              An eye-opening adventure deep inside the everyday materials that surround us.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Caesar's Last Breath\n              \n                \n                  Decoding the Secrets of the Air Around Us\n                \n              \n              Lively, witty, and filled with the astounding science of ordinary life, it tells the most enjoyable stories of air.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Sapiens\n              \n                \n                  A Brief History of Humankind\n                \n              \n              Bold, wide-ranging and provocative, Sapiens challenges everything we thought we knew about being human.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                How Not to Be Wrong\n              \n                \n                  The Power of Mathematical Thinking\n                \n              \n              Every modern human being should get familiar with the mathematical ways of thinking that applies to our everyday life. Not only does it help us avoid being fooled by statistics, it also teaches us how to think critically.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Consciousness and the Brain\n              \n                \n                  Deciphering How the Brain Codes Our Thoughts\n                \n              \n              A breathtaking look at the new science that can track consciousness deep in the brain.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Death's End\n              \n              \n              The sheer scale of this book and many original innovative ideas make this one of the most mind-blowing hard sci-fi out there today.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                The Three-Body Problem\n              \n              \n              While the characters are not very strong, many of the very unique ideas in this book will inspire a wonder about the universe that makes you ponder long after the ending.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                When\n              \n                \n                  The Scientific Secrets of Perfect Timing\n                \n              \n              Many interesting research about the science of timing.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Tricks Of The Mind\n              \n              \n              One of the best psychological illusionist of our time. Watch some of Derren Brown's shows, then you will understand why you'd want to read his book.\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Leonardo da Vinci\n              \n              \n              How can anyone not be inspired by his sense of wonder and curiosity?\n              \n            \n          \n      \n      \n          \n            \n              \n                  \n                    goodreads\n                  \n                  \n                  \n                    amazon\n                  \n              \n              \n                \n              \n            \n            \n              \n                Surely You're Joking, Mr. Feynman!\n              \n                \n                  Adventures of a Curious Character\n                \n              \n              This is a book that's worth reading and re-reading for a lifetime. It inspires the deepest curiosity and joy about finding out how the world works. It will make you want to become a physicist.\n              \n            \n          \n      \n\n\nNo matching items"
  },
  {
    "objectID": "TIL.html",
    "href": "TIL.html",
    "title": "TIL",
    "section": "",
    "text": "Subtle Bug: Variable Shadows Function\n\n\n\nPython\n\n\n\nIf we assign a variable with the same name as a function, even in a conditional statement, the function will be shadowed.\n\n\n\nZiyue Li\n\n\nApr 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGet Function from Modules Using Its Name\n\n\n\nPython\n\n\n\nHow to get the function defined in the current module using its name.\n\n\n\nZiyue Li\n\n\nJan 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n$() Command Substitution in Bash vs in Zsh\n\n\n\nCommand Line\n\n\nZsh\n\n\nBash\n\n\n\n$() concatenates the results into one single line in bash, but not in zsh.\n\n\n\nZiyue Li\n\n\nJan 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAppend and Prepend Characters in Python f-Strings\n\n\n\nPython\n\n\n\nA tip to quickly append and/or prepend multiple characters in f-strings.\n\n\n\nZiyue Li\n\n\nDec 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFixing the “Unable to Resolve Your Shell Environment” Problem in VSCode\n\n\n\nVSCode\n\n\nIDE\n\n\nZsh\n\n\n\nHow to fix the “unable to resolve your shell environment in a reasonable time” problem in VSCode.\n\n\n\nZiyue Li\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Get a List of Directories with Updated Files Since the Last Git Merge\n\n\n\nGit\n\n\nLinux\n\n\n\nUsing Linux commands to get a list of recently changed files and parse out the root directories.\n\n\n\nZiyue Li\n\n\nDec 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReplace Certain Lines in a Script Using Fileinput\n\n\n\nPython\n\n\n\nHow to replace certain lines and overwrite a text file using Python’s fileinput module.\n\n\n\nZiyue Li\n\n\nDec 6, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Set Function as Methods\n\n\n\nPython\n\n\n\nHow to set a function as bound method, class method and property.\n\n\n\nZiyue Li\n\n\nDec 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccess Data in Installed Python Package\n\n\n\nPython\n\n\n\nHow to access data files in installed python packages.\n\n\n\nZiyue Li\n\n\nNov 30, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccess Internet from Private Subnet in VPC\n\n\n\nAWS\n\n\nNetwork\n\n\n\nHow to setup AWS VPC so we can access internet from the private subnet.\n\n\n\nZiyue Li\n\n\nNov 23, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInfinite Recursion When Using store_attr and Overwriting __getattr__\n\n\n\nPython\n\n\nFastai\n\n\n\nAn infinite recursion when overwriting __getattr__ while store_attr is used.\n\n\n\nZiyue Li\n\n\nNov 16, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the Training Loop and CallBacks\n\n\n\nData Science\n\n\nPython\n\n\nAI\n\n\nFastai\n\n\n\nAn easy way to show the structure of the training loop and where callbacks are called in Fastai.\n\n\n\nZiyue Li\n\n\nNov 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPip Install from a Private Repo\n\n\n\nPython\n\n\n\nHow to pip install from a private repo\n\n\n\nZiyue Li\n\n\nNov 6, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2020-05-24-deriving_the_kelvin_wake_pattern.html",
    "href": "posts/2020-05-24-deriving_the_kelvin_wake_pattern.html",
    "title": "Deriving the Kelvin Wake Pattern",
    "section": "",
    "text": "Kelvin wake is the pattern generated by objects moving through deep waters at a constant speed.\n\nIn Feynman’s lecture 1, he mentioned that if one is clever enough, one can derive the Kelvin wake pattern from the fact that the pattern of the waves is stationary relative to the constant velocity of the boat; any other pattern would get lost from the boat. This post attempts to lay out the details of this derivation.\n\n\nHere I assume the reader has a basic understanding of the phase velocity and group velocity.\nThe phase velocity is the velocity at which the actual wave amplitudes travel, and the group velocity is the velocity at which the wave groups travel. The group velocity for water goes half as fast as the phase. This means, if one follows a particular crest of the water waves, they will find it moves forward in the group and gradually gets weaker and dies out in the front, and a weaker one in the back appears mysteriously and gets stronger, as show in the following demonstration:\n\n\n\nBy Becarlson - Own work, CC BY-SA 4.0, Link\n\n\n\n\n\nI will also take as a given the wave velocities in deep water:\n\\[\\begin{aligned}\nv_{phase}&=\\frac{\\omega}{k}=\\sqrt{\\frac{g\\lambda}{2\\pi}}=\\sqrt{\\frac{g}{k}}, \\\\\nv_{group}&=\\frac{d \\omega}{d k}=\\frac{1}{2}\\sqrt{\\frac{g\\lambda}{2\\pi}}=\\frac{1}{2}\\sqrt{\\frac{g}{k}}.\n\\end{aligned}\\]\nNotice that the phase velocity is twice the group velocity.\nIf you’re interested, a simple explanation of the above formula is given by Feynman in his physics lectures 2."
  },
  {
    "objectID": "posts/2020-05-24-deriving_the_kelvin_wake_pattern.html#phase-velocity-and-group-velocity",
    "href": "posts/2020-05-24-deriving_the_kelvin_wake_pattern.html#phase-velocity-and-group-velocity",
    "title": "Deriving the Kelvin Wake Pattern",
    "section": "",
    "text": "Here I assume the reader has a basic understanding of the phase velocity and group velocity.\nThe phase velocity is the velocity at which the actual wave amplitudes travel, and the group velocity is the velocity at which the wave groups travel. The group velocity for water goes half as fast as the phase. This means, if one follows a particular crest of the water waves, they will find it moves forward in the group and gradually gets weaker and dies out in the front, and a weaker one in the back appears mysteriously and gets stronger, as show in the following demonstration:\n\n\n\nBy Becarlson - Own work, CC BY-SA 4.0, Link"
  },
  {
    "objectID": "posts/2020-05-24-deriving_the_kelvin_wake_pattern.html#water-waves",
    "href": "posts/2020-05-24-deriving_the_kelvin_wake_pattern.html#water-waves",
    "title": "Deriving the Kelvin Wake Pattern",
    "section": "",
    "text": "I will also take as a given the wave velocities in deep water:\n\\[\\begin{aligned}\nv_{phase}&=\\frac{\\omega}{k}=\\sqrt{\\frac{g\\lambda}{2\\pi}}=\\sqrt{\\frac{g}{k}}, \\\\\nv_{group}&=\\frac{d \\omega}{d k}=\\frac{1}{2}\\sqrt{\\frac{g\\lambda}{2\\pi}}=\\frac{1}{2}\\sqrt{\\frac{g}{k}}.\n\\end{aligned}\\]\nNotice that the phase velocity is twice the group velocity.\nIf you’re interested, a simple explanation of the above formula is given by Feynman in his physics lectures 2."
  },
  {
    "objectID": "posts/2020-05-24-deriving_the_kelvin_wake_pattern.html#footnotes",
    "href": "posts/2020-05-24-deriving_the_kelvin_wake_pattern.html#footnotes",
    "title": "Deriving the Kelvin Wake Pattern",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFeynman Lectures on Physics Volume 1, Chapter 51.↩︎\nFeynman Lectures on Physics Volume 1, Chapter 51.↩︎\nKelvin wake pattern at large Froude numbers↩︎"
  },
  {
    "objectID": "posts/2014-11-22-black-hole-physics-in-interstellar.html",
    "href": "posts/2014-11-22-black-hole-physics-in-interstellar.html",
    "title": "Black Hole Physics in Interstellar",
    "section": "",
    "text": "Introduction\nA rotating black hole is needed to replicate the effects in the movie. Here we use the Kerr metric for the spinning black hole:\n\\[ds^{2}=-\\left(1-\\dfrac{2 M r}{\\rho^{2}}\\right)dt^{2}-\\dfrac{4 M a r \\sin^{2}\\theta}{\\rho^{2}}d\\phi dt+ \\dfrac{\\rho^{2}}{\\Delta}dr^{2}+\\rho^{2}d\\theta^{2}+\\left(r^{2}+a^{2}+\\dfrac{2M r a^{2}\\sin^{2}\\theta}{\\rho^{2}} \\right)d\\phi^{2}, \\]\nwhere \\(a\\equiv J/M\\), \\(\\rho^{2}\\equiv r^{2}+a\\cos^{2}\\theta\\), \\(\\Delta \\equiv r^{2}-2M r+a^{2}.\\)\nIn this post, I set \\(c=G=1\\) unless otherwise specified. One needs to restore \\(c\\) and \\(G\\) factors in the results to obtain values in the standard units, for example, \\(r=M\\) means \\(r=MG/c^2.\\) For detailed discussion please see reference [1].\n\n\nSpinning Rate of the Black Hole\n[Derived from Time Dilation Factor at the Innermost Stable Circular Orbit (ISCO)]\nIn the movie, 1 hour on Miller’s planet equals 7 years on earth. To get that time dilation effect, one normally needs to be close enough to the black hole. And because Miller’s planet is in a stable orbit as suggested in the movie, there’s a limit to how close it can be to the black hole. Another way to generate time dilation effects is through the spinning of the black hole. In the following calculation, we will show that to get the time dilation at the innermost stable circular orbit, the black hole needs to spin super fast.\nWe assume that Miller’s planet is orbiting in the equatorial plane \\((\\theta=\\pi/2)\\), so that \\(\\rho\\rightarrow r\\), \\(\\sin\\theta\\rightarrow1\\), \\(\\cos\\theta\\rightarrow0,\\) and the metric becomes\n\\[ds^{2}=-\\left(1-\\dfrac{2 M r}{r^{2}}\\right)dt^{2}-\\dfrac{4 M a }{r}d\\phi dt+ \\dfrac{r^{2}}{\\Delta}dr^{2}+\\rho^{2}d\\theta^{2}+\\left( r^{2}+a^{2}+\\dfrac{2M a^{2}}{r} \\right)d\\phi^{2}.\\]\nThe horizon is at [2]\n\\[r_{hr}=M+ \\sqrt{M^{2}-a^{2}}.\\]\nThe time dilation for a stable circular orbit is [2]\n\\[\\dfrac{dt}{d\\tau}=\\dfrac{a \\sqrt{M}+r^{3/2}}{\\sqrt{2 a \\sqrt{M} r^{3/2}-3 M r^2+r^3}}.\\]\nAnd the innermost stable circular orbit (ISCO) is at \\(r=r_{ISCO}\\) which is a solution to the following equation [2]\n\\[0=1-6\\dfrac{M}{r}+8\\dfrac{a M^{1/2}}{r^{3/2}}-3\\dfrac{a^{2}}{r^{2}}.\\]\nPlotting \\(r_{rh}, r_{ISCO}\\) and \\(\\dfrac{dt}{d\\tau}\\) as functions of \\(r\\) and \\(a\\), we get\n\n\n\nThe red line indicates the location of the black hole horizon, the orange line indicates the location of the ISCO, and the blue curve gives the time dilation factor as a function of coordinate \\(r\\). This plot is generated for \\(a=0.8M\\). As \\(a\\) increases, ISCO moves closer to the horizon, and the time dilation at ISCO becomes bigger. Therefore, to get the extreme time dilation of 1 hour equals 7 years as depicted in the movie, the black hole has to spin very fast, and \\(a\\) takes almost its extremal value \\(M.\\) We now proceed to derive this spin rate.\nWe parametrize \\(a\\) in the following way:\n\\[a=M(1-\\epsilon), \\] where \\(\\epsilon\\) is very small. With the equations quoted above, it follows that [2]\n\\[r_{hr}=M(1+\\sqrt{2\\epsilon}), \\]\n\\[r_{ISCO}=M[1+(4\\epsilon)^{1/3}].\\]\nThe time dilation at this \\(r_{ISCO}\\) is therefore\n\\[\\left.\\dfrac{dt}{d\\tau}\\right|_{ISCO}=\\dfrac{2}{\\sqrt{3}}\\left(\\dfrac{2}{\\epsilon}\\right)^{1/3}.\\]\nSetting it to \\(\\dfrac{\\text{7 years}}{\\text{1 hour}}=61320,\\) we find \\(\\epsilon=1.34 e -14.\\)\nAssuming Miller’s planet is at this innermost stable circular orbit, then this is the appropriate \\(\\epsilon\\) value for the movie. Therefore the black hole in the movie is spinning at a rate that’s only 100 trillionths away from the maximum. And the horizon and innermost stable orbit are at \\(r_{hr}=1.00000016M,\\) and \\(r_{ISCO}=1.00004M.\\)\n\n\nMass of the Black Hole\n[Derived From Tidal Force Balance]\nThe tidal force generated by the black hole across Miller’s planet must be smaller than the inward gravitational acceleration on the planet’s surface generated by the planet’s mass, otherwise, the planet would be torn apart. Using this fact, we can derive the limit to the mass of the black hole.\nFirst, let’s derive the tidal force generated across Miller’s planet. Two conserved quantities can be found respectively, because the metric has a time translation symmetry under \\(t\\rightarrow t+\\delta t\\) and azimuthal symmetry under \\(\\phi\\rightarrow \\phi+\\delta\\phi\\) (see [1, 2] and [here]):\n\\[e=\\dfrac{1 - 2M/r + a M^{1/2}/r^{3/2}}{\\sqrt{1 - 3M/r + 2 a M^{1/2}/r^{3/2}}},\\]\n\\[l=\\dfrac{M^{1/2}r^{1/2}-2 a M/r + M^{1/2}a^{2}/r^{3/2}}{\\sqrt{1 - 3M/r + 2aM^{1/2}/r^{3/2}}}.\\]\nPlugging in the \\(r_{ISCO}\\) and \\(a\\) values derived for this movie, one gets\n\\[e=0.57737,\\]\n\\[l=1.15474M,\\]\nfor the innermost stable circular orbit.\nThe radial velocity at \\(r\\) is given by [1]\n\\[\\dfrac{dr}{d\\tau}=\\sqrt{e^2-1+\\dfrac{2 M}{r}-\\dfrac{l^2-a^2 \\left(e^2-1\\right)}{2 r^2}+\\dfrac{2 M (l-a e)^2}{r^3}}.\\]\nThe gravitational acceleration is obtained by\n\\[g=\\dfrac{d^{2}r}{d\\tau^{2}}=\\dfrac{d^{2}r}{d\\tau dr}\\dfrac{dr}{d\\tau}, \\]\nso the gravitational difference across the radius of Miller’s planet \\(r_{Miller}\\) in the radial direction is\n\\[g_{tidal}=\\dfrac{dg}{dr}r_{Miller}=\\dfrac{3c^{6}}{M^{2}G^{2}}r_{Miller}, \\]\nwhere c and G are restored in the last step and \\(r_{ISCO}=1.00004M\\) is used. Notice that this differs from Kip Thorne’s formula because he used the familiar Newtonian gravitational acceleration generated by a mass at rest (\\(GM/R^2\\)), which gives the tidal force\n\\[g_{tidal}=\\dfrac{2 G M}{R^{3}}r_{Miller}=\\dfrac{2c^{6}}{M^{2}G^{2}}r_{Miller}, \\]\nwhere \\(R=r_{ISCO}\\simeq M\\) is used and c and G restored in the last step. Also, notice that because we assume the\nOn the other hand, the gravitational acceleration produced by Miller’s planet on the surface is\n\\[g_{Miller}=G\\dfrac{\\dfrac{4\\pi}{3}r^{3}\\rho}{r^{2}}=\\dfrac{4\\pi}{3}G r\\rho.\\]\nThe condition that tidal force does not rip apart Miller’s planet is\n\\[g_{Miller}&gt;g_{tidal}.\\]\nWith \\(\\rho=10000\\; kg/m^{3}\\) (number chosen by Kip Thorne for that of compressed rock), our tidal force would give\n\\[M_{bh}&gt;\\dfrac{3 c^{3}}{\\sqrt{4\\pi G^{3}\\rho}}=4.2e38\\; kg\\]\nor about the same as 210 million suns, while Kip Thorne’s tidal acceleration would result in\n\\[M_{bh}&gt;\\dfrac{\\sqrt{3}c^{3}}{\\sqrt{2\\pi G^{3}\\rho}}=3.4e38\\; kg\\]\nor about the same as 170 million suns.\nKip Thorne chose the mass of the black hole to be about 100 million suns as an approximation in his book, acknowledging that it should be 200 million suns. So for the sake of comparison, we will also use \\(M_{bh}=1e8 M_{sun}=1.99e38\\; kg\\) from now on.\nFor later convenience, we here define a distance unit corresponding to this black hole mass:\n\\[r_{unit}=\\dfrac{M_{bh} G}{c^{2}}=1.47e8\\; km, \\] which is about the same as the earth-sun distance.\n\n\nPosition of Miller’s Planet and the Parking Orbit\nTo get a sense of relative scale, we can ask: what are the radial distances of Miller’s planet and the parking orbit to the event horizon of the black hole?\nChris Nolan wanted the parking orbit to have modest time dilation relative to the earth, so in Kip’s interpretation, he chose the parking orbit at \\(r_{parking}=10M_{bh}=10r_{unit}.\\) Plugging this value into the \\(dt/d\\tau\\), we find the time dilation factor at this orbit to be about 1.2 (compared to earth time), which is reasonable.\nNote that because of the distortion in space, the circumference of the orbit is much less than \\(2\\pi\\) times the radial proper distance to the center of the black hole (the distance traveling on the membrane in the following figure). We reduce the 3-dimensional space to 2-dimension, and use the third direction to show what our space looked like in a higher dimension:\n\n\n\nThe yellow circle is the parking orbit for Endurance, the blue circle is the orbit for Miller’s planet, and the black circle at the bottom is the horizon. We see that because of the space distortion, even though the \\(r_{ISCO}\\) value is very close to \\(r_{hr}\\) (which produces similar radii for the circles), the proper distance between them (the distance on this “membrane” traversed by the spaceship) is much larger than expected.\nThe radius of the circle is the proper distance of the orbit divided by \\(2\\pi\\), and is given by \\(g_{\\phi\\phi}\\) of the metric \\(R=\\sqrt{\\frac{2 a^2 M}{r}+a^2+r^2}\\). Note that \\(R&gt;r\\) due to the spinning of the black hole (\\(a\\neq0\\)). For the parking orbit, \\(R_{parking}\\approx10M_{bh}\\approx10r_{unit}\\), the same as the coordinate \\(r\\). For Miller’s planet and the horizon, \\(R_{ISCO}\\approx R_{hr}=2M_{bh}=2r_{unit}\\), twice the coordinate \\(r_{ISCO}\\) and \\(r_{hr}.\\)\nWe now wish to calculate the proper distance between \\(r_{ISCO}\\) and \\(r_{hr}\\), and the proper distance between \\(r_{ISCO}\\) and \\(r_{parking}\\). From the metric, we have\n\\[\\dfrac{ds}{dr}=\\sqrt{\\dfrac{r^2}{a^2-2 M r+r^2}}.\\]\nWe use the parametrization of \\(r_{ISCO}=M_{bh}(1+\\xi_{ISCO})\\), \\(r_{hr}=M_{bh}(1+\\xi_{hr})\\) and \\(a=M_{bh}(1-\\epsilon)\\). The integration produces\n\\[\\int_{M_{bh}(1+\\xi_{ISCO})}^{M_{bh}(1+\\xi_{hr})}\\dfrac{ds}{dr}dr=M_{bh}\\log\\left[\\dfrac{\\xi_{ISCO} +\\sqrt{\\xi_{ISCO} ^2+\\epsilon ^2-2 \\epsilon}}{\\xi_{hr} +\\sqrt{\\xi_{hr} ^2+\\epsilon ^2-2 \\epsilon}}\\right]\\simeq6.1M_{bh}=6.1r_{s}, \\]\nor 6.1 times the earth-sun distance. Direct numerical integration for the proper distance between \\(r_{ISCO}\\) and \\(r_{parking}\\) gives 21.4 times the earth-sun distance.\n\n\nOrbital Periods at \\(r_{ISCO}\\) and \\(r_{parking}\\)\nThe angular velocity is given by [2]\n\\[\\omega=\\dfrac{d\\phi}{dt}=\\dfrac{\\sqrt{M}}{a \\sqrt{M}+r^{3/2}}\\dfrac{c^{3}}{G}, \\]\nwhere c and G are restored.\nWe immediately obtain \\(\\omega_{ISCO}=0.001\\; s^{-1}\\) and \\(\\omega_{parking}=0.000062\\; s^{-1}\\), corresponding to 1.7 hours for Miller’s planet and 28 hours for the parking orbit respectively. Because the time slows down a factor of 61320 on Miller’s planet, the 1.7 hour period measured on the planet would be only 0.1 second, which means the planet travels around this \\(2\\pi R_{ISCO}=8\\pi r_{unit}\\) circumference 10 times per second! That seems super fast! In fact, it’s faster than the speed of light! How can that be? Well, as Kip explains in his book, because of the space whirl induced by the black hole’s fast spin, this is slower than the local speed of light, and because of the free-falling motion, the centripetal force felt by the planet is negligible compared to the more important tidal force.\n\n\nRocking Period of Miller’s Planet Induced by the Tidal Force\nIn one of Kip’s interpretations, the waves are possibly created by the rocking of the planet under the tidal force of the black hole. As he explained in his book, the planet has its face almost locked to the black hole, because otherwise the mantle would be pulverized under the tidal force. But, to produce the huge waves seen in the movie, the planet needs to rock back and forth a bit.\nI now attempt to calculate the period of this rocking motion in a very simplified model.\n\n\n\nUnder the tidal force, Miller’s planet would be stretched and squeezed to an ellipsoid shape. The red lines indicate the stretching direction and the blue lines indicate the squeezing direction. Let’s say the planet’s semi-major axis has length \\(l,\\) then the torque produced by each half hemisphere has the lever arm distance of \\(l/2\\theta.\\) So the torque produced by the tidal force in the black hole radial direction can be approximated to be \\(-\\dfrac{m}{2}g_{tidal}\\dfrac{l}{2}\\theta\\), where \\(m/2\\) is the mass of each hemisphere.\nThere is another torque produced by the squeezing force in the orbital direction (see Kip Thorne’s book), but here instead of calculating that, we take a guess, and approximate it to be the same amount as the torque above. Therefore, the total torque is \\(-\\dfrac{m}{2}g_{tidal}l\\theta.\\) To simplify the problem further, we use the moment of inertia formula for a solid ball instead of an ellipsoid and approximate \\(r_{miller}\\approx l\\), i.e. \\(I=\\dfrac{2}{5}m l^{2}.\\) We then have\n\\[\\dfrac{2}{5}m l^{2}\\dfrac{d^{2}\\theta}{dt^{2}}+\\dfrac{m}{2}g_{tidal}l\\theta=0.\\]\nThe period of the oscillation is\n\\[\\omega=\\sqrt{\\dfrac{5}{4}\\dfrac{c^{6}}{G^{2}M}}, \\]\nwhere c and G are restored. Plugging in \\(M=M_{bh}\\), this gives 0.0023 per second, or a period of 27 minutes, about half an hour. This differs from Kip’s result of 1 hour, which is also the time between waves used in the movie. But considering the estimation I did was quite poor, I’m happy with the result.\n\n\nReferences\n[1] J. B. Hartle, Gravity: An Introduction to Einstein’s General Relativity (Benjamin Cummings, 2003).\n[2] S. Chandrasekhar, The Mathematical Theory of Black Holes (Clarendon Press, Oxford University Press)."
  },
  {
    "objectID": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html",
    "href": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html",
    "title": "Tips for Configuring a Quarto Website",
    "section": "",
    "text": "It took me some time to migrate to Quarto. Here are some the tips that might be helpful if you are thinking about doing the same."
  },
  {
    "objectID": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#different-sidebars-for-different-contents",
    "href": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#different-sidebars-for-different-contents",
    "title": "Tips for Configuring a Quarto Website",
    "section": "1 Different Sidebars for Different Contents",
    "text": "1 Different Sidebars for Different Contents\nOn this website, you will see multiple sections: Posts, TIL, Books … Many of them have their own sidebars. For example, see one of the posts in TIL. On the left-hand side is the sidebar to jump to other posts quickly.\n\nThis is easy to set up by simply having multiple sidebars in _quarto.yml. However, there seems to be a bug when you only have one sidebar configured. That one sidebar will show up across your website, even for pages unrelated to that sidebar.\nAs of this writing, an easy way to solve this is to make another empty sidebar:\nsidebar:\n  - id: til\n    title: TIL\n    contents:\n      - section: '2022'\n        contents:\n        - text: Nbdev_ignore\n          href: TIL/2022/2022-11-23-aws-private_subnet_setup.ipynb\n        - text: Whisper2Subtitles\n          href: TIL/2022/2022-11-16-fastai-store_attr_infinite_recursion.ipynb\n        - text: DreamBooth\n          href: TIL/2022/2022-11-15-fastai-show_training_loop.ipynb\n  - id: empty sidebar"
  },
  {
    "objectID": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#enable-line-numbers-in-code-blocks",
    "href": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#enable-line-numbers-in-code-blocks",
    "title": "Tips for Configuring a Quarto Website",
    "section": "2 Enable Line Numbers in Code Blocks",
    "text": "2 Enable Line Numbers in Code Blocks\nSome useful settings for code blocks in _quarto.yml:\nformat:\n  html:\n    code-line-numbers: \"1\"\n    code-block-bg: true\n    code-block-border-left: true\n    code-copy: true\n    code-fold: false"
  },
  {
    "objectID": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#add-a-comment-section-that-supports-latex",
    "href": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#add-a-comment-section-that-supports-latex",
    "title": "Tips for Configuring a Quarto Website",
    "section": "3 Add A Comment Section that Supports Latex",
    "text": "3 Add A Comment Section that Supports Latex\n\nGiscus is a comments system powered by GitHub Discussions. It supports Latex, so that visitors can type math equations in the comment section.\nMake sure you configure the repository and the Discussion Category on Giscus. This will generate the script code. We don’t need to copy that code, but we do need to note the data-repo-id, and data-category-id.\nTo enable it for a page, include the following in the YAML front matter:\ncomments:\n  giscus:\n    repo: &lt;GitHub Repo for Your Quarto Website&gt;\n    repo-id: &lt;Your data-repo-id&gt;\n    category: &lt;The Discussion Category&gt;\n    category-id: &lt;Your data-category-id&gt;\n    mapping: \"title\"\n    reactions-enabled: true\n    loading: lazy\n    input-position: \"top\"\n    theme: \"preferred_color_scheme\""
  },
  {
    "objectID": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#add-rss-feed",
    "href": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#add-rss-feed",
    "title": "Tips for Configuring a Quarto Website",
    "section": "4 Add RSS Feed",
    "text": "4 Add RSS Feed\n\n\nAdd feed: true in the listing page Include a feed for your listing by including the feed option in your listing page:\nlisting:\n  contents: posts\n  feed: true\nAn RSS file will automatically be generated using the name of the the file in the same location as the listing page. For example, index.qmd will produce a feed at index.xml.\nInclude the path to the xml file\nWe need to explicitly include links to these xml files. On this website, I created 3 RSS feeds: Posts, TIL and Projects. I included them in _quarto.yml under a menu on the right side of the navigation bar:\nwebsite:\n  navbar:\n    right:\n      - icon: rss\n        menu:\n        - text: Subscribe to Posts\n            icon: rss\n            href: https://feynlee.github.io/curiosity-notes/index.xml\n            aria-label: Posts RSS\n        - text: Subscribe to TIL\n            icon: rss\n            href: https://feynlee.github.io/curiosity-notes/TIL.xml\n            aria-label: TIL RSS\n        - text: Subscribe to Projects\n            icon: rss\n            href: https://feynlee.github.io/curiosity-notes/projects.xml\n            aria-label: Projects RSS"
  },
  {
    "objectID": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#add-social-share-buttons",
    "href": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#add-social-share-buttons",
    "title": "Tips for Configuring a Quarto Website",
    "section": "5 Add Social Share Buttons",
    "text": "5 Add Social Share Buttons\n\nThere’s already an option to add social share buttons through the Quarto extension quarto-social-share. However, I’d like to use sharethis, and I want to make them appear above the comment section, immediately after each post.\nAfter you configured the share buttons on sharethis, it will generate a header code and buttons code.\n\n5.1 Header Code\nFor the header code, we can include it in the header of the website, by adding the following in _quarto.yml:\nformat:\n  html:\n    header-includes: &lt;script type=\"text/javascript\" src=\"https://platform-api.sharethis.com/js/sharethis.js#property=**************&product=inline-share-buttons&source=platform\" async=\"async\"&gt;&lt;/script&gt;\n\n\n5.2 Buttons Code\nFor the buttons code, one could’ve included it at the bottom of each post manually, so that the share buttons appear there. However, I’d like to do this more efficiently, so I created an extension: code-insertion, which can insert any markdown/html code before and/or after a post.\nHere’s what you need to do to enable this:\n\nInstall Extension\nquarto add feynlee/code-insertion\nThis will install the extension under the _extensions subdirectory. If you’re using version control, you will want to check in this directory for your Quarto website.\nCreate a Markdown file to store the buttons code\nCreate a markdown file (html also works) _sharebuttons.md:\n&lt;div class=\"sharethis-inline-share-buttons pt-5\"&gt;&lt;/div&gt;\nThe pt-5 is a Bootstrap class to make sure there’s enough space between the post and the share buttons.\nMake sure to start the file name with an underscore, so that Quarto ignores it when generating htmls.\nEnable the filter in _metadata.yml for all posts\nIn the YAML front matter of a post, enable the code-insertion filter, and add insert-before-post and/or insert-after-post parameters that point to a markdown file with sections you want to insert before and/or after the post.\nCreate a _metadata.yml file under the folder that contains all of your posts. Any settings here will be shared by all posts. Enable the code-insertion filter:\nfilters:\n  - code-insertion\ninsert-after-post: _sharebuttons.md\nNote that you should put the path to your _sharebuttons.md file for insert-after-post. This will insert that code as the last block in your post, which is above the comment section."
  },
  {
    "objectID": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#add-an-annotation-tool",
    "href": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#add-an-annotation-tool",
    "title": "Tips for Configuring a Quarto Website",
    "section": "6 Add An Annotation Tool",
    "text": "6 Add An Annotation Tool\nYou can enable hypothes on your website so that visitors can highlight and annotate your posts.\ncomments:\n  hypothesis:\n    theme: clean\nThis is enabled for my website. You can see the Hypothesis UI at the far right of the page. You can also drag cursor over texts to make your own highlights and annotations on this page."
  },
  {
    "objectID": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#enable-anchor-sections",
    "href": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#enable-anchor-sections",
    "title": "Tips for Configuring a Quarto Website",
    "section": "7 Enable Anchor Sections",
    "text": "7 Enable Anchor Sections\nHover over a section title to see an anchor link. An anchor link makes it possible to share and reference the exact position of the specified section. Enable/disable this behavior with:\nformat:\n  html:\n    anchor-sections: true\nAnchor links are also automatically added to figures and tables that have a cross reference defined."
  },
  {
    "objectID": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#a-custom-listing-page",
    "href": "posts/2022-11-24-tips_for_configuring_a_quarto_website.html#a-custom-listing-page",
    "title": "Tips for Configuring a Quarto Website",
    "section": "8 A Custom Listing Page",
    "text": "8 A Custom Listing Page\nThe Books page on this website is created with a custom listings page. With EJS Template, one can create a very customized listings page to suit one’s needs.\nSorting, filtering and pagination can also be enabled for your listings page with very little effort."
  },
  {
    "objectID": "posts/2019-08-25-cosmological-perspective.html",
    "href": "posts/2019-08-25-cosmological-perspective.html",
    "title": "Cosmological Perspective",
    "section": "",
    "text": "“Cosmic Horizons”"
  },
  {
    "objectID": "posts/2019-08-25-cosmological-perspective.html#co-moving-distance",
    "href": "posts/2019-08-25-cosmological-perspective.html#co-moving-distance",
    "title": "Cosmological Perspective",
    "section": "Co-moving Distance",
    "text": "Co-moving Distance\nTo disentangle the effects of property 1 and property 2, we construct so-called “co-moving coordinates” to mark the expansion and contraction of the space itself. The co-moving distance is the distance measured on this coordinate system and is therefore fixed relative to space itself. The lattice spacing between the coordinates indicates how space itself is changing in time. And the change in the co-moving coordinates indicates a real motion relative to the local space. We denote the co-moving coordinates with the letter \\(r\\) and the lattice spacing with \\(a(t)\\), as a function of time. The co-moving distance will be denoted as \\(D_{C}\\)."
  },
  {
    "objectID": "posts/2019-08-25-cosmological-perspective.html#proper-distance",
    "href": "posts/2019-08-25-cosmological-perspective.html#proper-distance",
    "title": "Cosmological Perspective",
    "section": "Proper Distance",
    "text": "Proper Distance\nProper distance is the “real” distance between two objects, i.e. the lattice spacing times the co-moving distance between these two objects. In Fig. 1, the co-moving distance between coordinates 1 and 2 is always 1, but the proper distance \\(a(t)\\) changes from 1 unit to 3 units because of the expansion. The proper distance will be denoted as \\(D_P\\).\nNotice that for objects fixed in space, because it is easy to convert between the co-moving distance and the proper distance, most of the time it’s not necessary to specify which one we are talking about. For example, “the distance between A and B” can be understood as either the co-moving or the proper distance, and it’s easy to work out one from the other. In that case, we will just say “distance”."
  },
  {
    "objectID": "posts/2019-08-25-cosmological-perspective.html#traveling-distance",
    "href": "posts/2019-08-25-cosmological-perspective.html#traveling-distance",
    "title": "Cosmological Perspective",
    "section": "Traveling Distance",
    "text": "Traveling Distance\nThis introduces the first thought experiment: in a universe where space varies with time, the proper distance an object traveled from point A at time \\(t_{A}\\) to point B at time \\(t_{B}\\) is in general not the same as the proper distance at time \\(t_A\\) nor \\(t_B\\).\nLet’s say space is expanding. As the object travels from A to B, the space in front of it is constantly increasing, so that the distance it has to travel to reach B is certainly larger than the original proper distance at time \\(t_{A}\\). At the same time, the space behind it, i.e. the space it has already traveled, is also constantly expanding, so that the proper distance at time \\(t_{B}\\), namely \\(D_{P}(t_{B})=a(t_{B})\\|r_{B}-r_{A}\\|\\), is larger than the distance it traversed. So in this case we have \\(D_{P}(t_A)&lt;D_{T}&lt;D_{P}(t_B)\\), where we denoted the traveling distance with \\(D_{T}\\) and the proper distance between AB at time \\(t_A\\) and \\(t_B\\) with \\(D_{P}(t_A)\\) and \\(D_{P}(t_B)\\).\n\n\n\nFig. 1 A view of an isometric embedding of part of the visible universe over most of its history. The vertical direction is the time and the blue circles represent the space at a certain cosmological time. This figure shows how a light ray (red line) can travel an effective distance of 28 billion light-years (orange line) in just 13 billion years of cosmological time. Here the 13 billion light-years are the traveling distance and the 28 billion light-years are the proper distance between AB at the end time. [This demonstration is taken from the section “Measuring distances in expanding space” in this wiki page: Metric expansion of space].\n\n\nOnce you figure this out, it’s easy to understand the following seemingly counterintuitive phenomena:\n\nWhen we look at objects that are currently 1 billion light-years away, we see what they were like LESS than 1 billion light-years away.\nFor us to see what objects that are currently 1 billion light-years away look like, we will have to wait MORE than 1 billion years.\n\nWhenever we talk about distance, we need to understand which distance at which time we are talking about. For example, when we say that we can see light from objects 28 billion light-years away even though the universe is only 13 billion years ago, what we mean is that we can see light emitted 13 billion years ago from objects that were less than 13 billion light-years away from us when the light was emitted, but now are 28 billion light-years away from us. We don’t currently see the light currently emitted by objects that are currently 28 billion light-years away."
  },
  {
    "objectID": "posts/2019-08-25-cosmological-perspective.html#the-unfortunate-definition-of-accelerating-expansion",
    "href": "posts/2019-08-25-cosmological-perspective.html#the-unfortunate-definition-of-accelerating-expansion",
    "title": "Cosmological Perspective",
    "section": "The Unfortunate Definition of “Accelerating Expansion”",
    "text": "The Unfortunate Definition of “Accelerating Expansion”\nWhether the expansion of the universe is accelerating or decelerating is defined by \\(\\ddot{a}(t)\\). This is defined from the perspective that if we observe the space expansion between two fixed points on the co-moving coordinate system, whether we see the rate of space added is increasing or decreasing. But if we think about this for a minute, we will realize that more spaces may be added later, simply because there are more spaces between the two points later. In other words, the textbook definition of “accelerating expansion” is the “apparent accelerating expansion”.\nThis definition is very unfortunate, since it does not capture the “intrinsic expansion rate” of the universe and thus induces a lot of confusion, especially when we consider the event horizon of the universe, as we will see below."
  },
  {
    "objectID": "posts/2019-08-25-cosmological-perspective.html#intrinsic-expansion-rate-the-hubble-parameter",
    "href": "posts/2019-08-25-cosmological-perspective.html#intrinsic-expansion-rate-the-hubble-parameter",
    "title": "Cosmological Perspective",
    "section": "Intrinsic Expansion Rate: the Hubble Parameter",
    "text": "Intrinsic Expansion Rate: the Hubble Parameter\nTo get the “intrinsic expansion rate”, we need to remove the dependence on the changing distance. This can be achieved by dividing the apparent velocity of a distant co-moving object by the proper distance in between:\n\\[H=\\dfrac{r\\dot{a}(t)}{ra(t)}=\\dfrac{\\dot{a}(t)}{a(t)},\\]\nwhere \\(\\dot{a}(t)\\) is the time derivative of \\(a(t)\\). For those interested, Young’s modulus in solid-state physics is defined in a similar way to get rid of the length dependence so that it reflects the property of the material.\nIn other words, the Hubble parameter gives the true expansion rate.\nTo make it clearer why using \\(\\ddot{a}(t)\\) to understand expansion is a bad idea, think of it this way: let’s say the Hubble parameter is not changing with time, which means the characteristic expansion of the universe is not speeding up nor slowing down. But since at a later time, \\(a(t)\\) itself becomes larger, the induced apparent velocity at that larger proper distance will become larger, and thus \\(\\ddot{a}(t)&gt;0\\), and we get the conclusion that the universe’s expansion is “accelerating”. That “acceleration” is relative to the coordinate system set up from the very beginning. If instead you compare the expansion of space now to the expansion of space between objects with the same amount of proper distance in between a long time ago, the expansion can be slower.\nHow does \\(a(t)\\) change if the intrinsic expansion rate is constant? We can solve \\(H=\\dot{a}(t)/a(t)=\\beta\\) to get \\[a(t)=e^{\\beta t}.\\] In other words, at a constant intrinsic expansion rate, \\(a(t)\\) should be increasing exponentially. Therefore, any slower change of \\(a(t)\\) corresponds to a decrease in the intrinsic expansion rate. One can check this easily with \\(a(t)=t^2\\). Obviously \\(a(t)\\) increases at an accelerating rate, but the “intrinsic expansion rate” \\(H=\\dot{a}/a=2/t\\) is actually decreasing. Said in another way, a constant \\(H\\) corresponds to an exponentially increasing \\(a(t)\\), while a decreasing \\(H\\) corresponds to slower increase in \\(a(t)\\).\nThe Hubble parameter in our standard cosmology model changes as follows. It decreases quickly in the beginning, and then gradually approaches a constant. So initially \\(a(t)\\) increases at a rate slower than exponential, but eventually, \\(a(t)\\) expands exponentially.\n\n  \n\nFig. 2 An illustration of how the Hubble parameter changes in the standard model."
  },
  {
    "objectID": "posts/2019-08-25-cosmological-perspective.html#hubble-distance",
    "href": "posts/2019-08-25-cosmological-perspective.html#hubble-distance",
    "title": "Cosmological Perspective",
    "section": "Hubble Distance",
    "text": "Hubble Distance\nHubble distance is defined as the distance at which the receding velocity is the speed of light:\n\\[D_H=\\frac{c}{H}.\\]\nHowever, due to the space expansion, we can see objects that are currently moving with speed above the speed of light, beyond the Hubble distance, as explained below."
  },
  {
    "objectID": "posts/2019-08-25-cosmological-perspective.html#cosmic-event-horizon",
    "href": "posts/2019-08-25-cosmological-perspective.html#cosmic-event-horizon",
    "title": "Cosmological Perspective",
    "section": "Cosmic Event Horizon",
    "text": "Cosmic Event Horizon\nThe event horizon is the distance at which the photon emitted now will never reach us in the infinite future. One might naively think that this distance is the Hubble length. After all, the objects beyond the Hubble length are leaving us at speeds greater than the speed of light, so of course, their light can never reach us! Well, think again. \nWe will be able to see light emitted from some objects outside of our Hubble Sphere, thanks to the slowing down of the intrinsic expansion rate \\(H\\)!\n\nA Detour\nThis is very counter-intuitive. Before we go into the correct explanation, I want to spell out a couple of common traps people tend to fall into when thinking about this problem:\n\nAs hinted above, people assume that just because the photons emitted from those objects are now apparently moving away from us, and the expansion is “accelerating”, there’s no way that the light emitted from these objects will reverse their course and come towards us.\nWe already explained what “accelerating expansion” really means. So the above assumption translates to: because \\(a(t)\\) is accelerating, the apparent velocity of the object can only increase. The implicit assumption for that statement is that the apparent velocity of the object only depends on how \\(a(t)\\) changes. Is that true? No. The apparent velocity of the photon is composed of two parts:\n\nthe apparent velocity induced by the expansion of the universe, which is \\(r\\cdot \\dot{a}(t)\\), depends on both how \\(a(t)\\) changes and how its co-moving coordinates \\(r(t)\\) changes;\nthe local velocity of the photon, which is c.\n\nThe apparent velocity of the photon is therefore \\(r(t) \\cdot \\dot{a}(t)-c\\).\nJust because at one moment this value is positive (moving away from us), does not mean that it will stay that way. At the same time that \\(\\dot{a}(t)\\) is increasing, the co-moving distance \\(r\\) is decreasing because the photon is locally heading in our direction. The apparent velocity can potentially decrease if the decreasing \\(r\\) brings down the total apparent velocity, even though \\(\\dot{a}(t)\\) is increasing.\nOnce we understand how the apparent velocity also depends on the decreasing co-moving distance, people might assume that just because the apparent velocity might start decreasing, that will guarantee the photon can reach us.\nUnfortunately, the apparent velocity of a photon can slow down and never get to the point where the apparent velocity is flipped. It’s hard to show this without invoking some math, but one can conceptually understand that the changes of \\(r(t)\\) and \\(\\dot{a}(t)\\) can result in the apparent velocity \\(r(t) \\cdot \\dot{a}(t)-c\\) decreasing but never reaching zero.\n\n\n\nExplanation\nIt’s easy to see that reasoning using the apparent velocity is difficult and error-prone. Our first instinct and intuition lead us that way, probably because we are so used to thinking about motions in terms of how velocity changes. However, the dynamics in an expanding universe are more complex, because the velocity induced by the expansion is location-specific (it’s a function of relative distance), while the other local velocity is constant relative to space. This makes it very hard to imagine and reason about how the apparent velocity changes, since at the next moment, the location changes and the location-induced velocity changes.\nInstead of thinking in terms of velocity, let’s think in terms of the co-moving coordinates since it’s easier to see the effect of the local motion relative to this coordinate system.\nDuring a small time interval \\(dt\\), the photon travels a distance \\(cdt\\) in space, which gives \\(dr = c dt/a(t)\\) in terms of the co-moving distance. The proper distance at a cosmological time \\(t\\) corresponding to the total co-moving distance that can be traversed from time \\(t\\) to the infinite future is the definition of Event Horizon:\n\\[R_{EH} = a(t)\\int_{t}^{\\infty}\\dfrac{c dt}{a(t)}.\\]\nWhen the universe is expanding at a constant intrinsic rate, \\(a(t)=e^{\\beta t}\\), we have\n\\[R_{EH} = \\dfrac{c}{\\beta} = D_{H}.\\]\nThe Hubble Sphere coincides with the Event Horizon. It’s easy to understand then if the “intrinsic expansion rate” is not constant, but instead slowing down during the time the photon was traveling to us, it will be able to cover more ground, and therefore the Event Horizon will be larger than the Hubble distance.\nAs mentioned before, the intrinsic expansion rate of our universe is slowing down, resulting in the fact that we can observe objects outside of our current Hubble Sphere, even though the expansion rate as measured by \\(a(t)\\) is speeding up."
  },
  {
    "objectID": "posts/2019-08-25-cosmological-perspective.html#particle-horizon",
    "href": "posts/2019-08-25-cosmological-perspective.html#particle-horizon",
    "title": "Cosmological Perspective",
    "section": "Particle Horizon",
    "text": "Particle Horizon\nThe particle horizon describes the furthest distance we can see right now. And because it takes photon time to reach us and we are looking back in time as we look deeper into space, it should not be a surprise that we can see things that are currently beyond our current Hubble sphere and our current event horizon.\nIt’s very important to stress that we are not seeing what these objects look like right now since it takes time for the photon to travel to us. We are only seeing them as their younger selves when the distance to them was different.\nConfusingly, the particle horizon is not defined in terms of the co-moving distance of these objects, which never changes, nor is it defined as the proper distance at which the photon was emitted, but instead the current proper distance of these objects, even though we are not seeing them at the current proper distance right now:\n\\[R_{PH} = a(t)\\int_{0}^{t}\\dfrac{c dt}{a(t)}\\]\n\n     \n\nFig. 3 Demonstration of how Hubble sphere (green), Event horizon (red), light ray (yellow), and Particle horizon (blue) change with the cosmological time, plotted in both the co-moving distances (top) and the proper distances (bottom). The light ray shows how it is possible to observe photons outside of the Hubble sphere. The dotted lines indicate constant co-moving distances. The black horizontal line indicates our current universe, where the particle horizon &gt; the Event horizon &gt; the Hubble sphere. The standard cosmological model is assumed. Numerical values for parameters in the model: \\(H_0=67.8 \\text{km/s/Mpc}\\), \\(\\Omega_{\\Lambda}=0.7\\), \\(\\Omega_{M}=0.3\\), \\(\\Omega_{R}=\\Omega_K=0\\). [Mathematical notebook used to calculate the above curves: Hubble_Sphere_Horizons_and_Observable_Universe.nb.]"
  },
  {
    "objectID": "posts/2019-08-25-cosmological-perspective.html#observable-universe",
    "href": "posts/2019-08-25-cosmological-perspective.html#observable-universe",
    "title": "Cosmological Perspective",
    "section": "Observable Universe",
    "text": "Observable Universe\nOne should be extremely careful in understanding the concepts of the cosmic event horizon and the particle horizon. The cosmic event horizon is NOT the furthest distance one can see in the future. The furthest distance one can see in the future is the particle horizon in that future. As demonstrated in Fig. 3, the particle horizon is bigger than the cosmic event horizon at the present and in the future. The cosmic event horizon describes the boundary beyond which the events will never be observed, while the particle horizon describes the furthest distance one can see at a certain cosmological time.\nThe “observable universe” is defined by the particle horizon. This is the 93 billion light-years value quoted in this wikipedia picture.  According to Fig. 3, the size of the “observable universe” is getting bigger and bigger."
  },
  {
    "objectID": "posts/2019-08-25-cosmological-perspective.html#what-the-sky-looks-like-in-the-far-distant-future",
    "href": "posts/2019-08-25-cosmological-perspective.html#what-the-sky-looks-like-in-the-far-distant-future",
    "title": "Cosmological Perspective",
    "section": "What the Sky Looks Like In the Far Distant Future",
    "text": "What the Sky Looks Like In the Far Distant Future\nBecause the light rays always go all the way back in time, it means that we will always in theory get photons from the objects emitted in the past. So it is not correct to say that when objects move out of the event horizon, we will never see them again. In fact, we will always see their younger selves before they move beyond the event horizon. As illustrated by the light rays in Fig. 3, as time goes on, the light ray (yellow) infinitely approaches the event horizon line (red). This means, in the very far distant future, these objects will seem to be frozen at the time when they started to cross the event horizon, and we never see them actually cross it.\nAs a clarification, the event horizon should not be thought of as a distance, but different distances at different times (a world line in space-time diagram), as indicated by the red line in Fig. 3. When we say the objects seem to be frozen at the event horizon, we mean, when we look out into space, the younger selves of distant objects whose light reaches us slowly approach the time when they crossed the event horizon, but never get there. Therefore, we should always be able to see distant objects as their younger selves moving closer and closer to the event horizons at corresponding times, if we still exist.\nHowever, there’s another effect that we haven’t mentioned in this post: redshift. The wavelengths of photons emitted from the distant past will be stretched due to the expansion of space, so in the very distant future, even though we should still get photons from the distant past in theory, the large wavelengths of these photons will make it almost impossible to observe. This is the real reason why we won’t be able to these distant objects anymore, not because they already moved past the event horizon from our perspective.\nDoes that mean that the sky will look black in the distant future? Not if stars in our galaxy and nearby galaxies are still shining for some reason. Galaxies that are close enough to be gravitationally bound to our own when the universe expands will not be pushed away by the expansion, and could still be there. But then again, in the far distant future, stars might have already died. In that case, we won’t be able to see anything anymore."
  },
  {
    "objectID": "posts/2016-05-02-notes-for-learning-d3-js.html",
    "href": "posts/2016-05-02-notes-for-learning-d3-js.html",
    "title": "Study Notes for D3.js - 7 Basic Concepts to Grasp",
    "section": "",
    "text": "In this post, I summarize 7 basic concepts that I find very important to understand when learning D3."
  },
  {
    "objectID": "posts/2016-05-02-notes-for-learning-d3-js.html#compartmentalize-the-canvas-into-groups-g-tag",
    "href": "posts/2016-05-02-notes-for-learning-d3-js.html#compartmentalize-the-canvas-into-groups-g-tag",
    "title": "Study Notes for D3.js - 7 Basic Concepts to Grasp",
    "section": "1. Compartmentalize the canvas into groups (“g” tag)",
    "text": "1. Compartmentalize the canvas into groups (“g” tag)\nThink of the whole visualization as many small groups of elements. Each group can have its own group of elements. Use select and append to add tags. The first thing usually is to create an svg element (the canvas):\nvar svg = d3.select(\"body\")\n            .append(\"svg\")\n            .attr(\"width\", width)\n            .attr(\"height\", height)\nThen within the svg element, we can add many groups, for example, the legend itself is a group, within which we have two groups, each represents an entry in the legend:\nvar legend = svg.append('g')\n                .attr('class','legend')\n                .attr('transform', 'translate(' + (width-100) + \",\" + 20 + \")\")\n                .selectAll('g')\n                .data([\"Home Team\", \"Others\"])\n                .enter()\n                .append('g');"
  },
  {
    "objectID": "posts/2016-05-02-notes-for-learning-d3-js.html#set-positions-of-each-group-by-setting-attributes-transform-to-translatexy-for-that-group.",
    "href": "posts/2016-05-02-notes-for-learning-d3-js.html#set-positions-of-each-group-by-setting-attributes-transform-to-translatexy-for-that-group.",
    "title": "Study Notes for D3.js - 7 Basic Concepts to Grasp",
    "section": "2. Set positions of each group by setting attributes ‘transform’ to ‘translate(x,y)’ for that group.",
    "text": "2. Set positions of each group by setting attributes ‘transform’ to ‘translate(x,y)’ for that group.\nAs shown in the above legend example. Note that the canvas origin is at the upper left corner, so the y direction goes downwards instead of upwards."
  },
  {
    "objectID": "posts/2016-05-02-notes-for-learning-d3-js.html#bind-data-to-elements-by-selectall.datadata.enter.append",
    "href": "posts/2016-05-02-notes-for-learning-d3-js.html#bind-data-to-elements-by-selectall.datadata.enter.append",
    "title": "Study Notes for D3.js - 7 Basic Concepts to Grasp",
    "section": "3. Bind data to elements by ‘…selectAll.data(data).enter().append(…)’",
    "text": "3. Bind data to elements by ‘…selectAll.data(data).enter().append(…)’\nAs shown in the above legend example, ‘enter()’ returns placeholder elements for data that are not yet bound to any element, while ‘exist()’ returns elements that not yet bound to any data. ‘append’ then adds the element."
  },
  {
    "objectID": "posts/2016-05-02-notes-for-learning-d3-js.html#use-functions-to-assign-attributes-.attr",
    "href": "posts/2016-05-02-notes-for-learning-d3-js.html#use-functions-to-assign-attributes-.attr",
    "title": "Study Notes for D3.js - 7 Basic Concepts to Grasp",
    "section": "4. Use functions to assign attributes ‘.attr’",
    "text": "4. Use functions to assign attributes ‘.attr’\nlegend.append(\"text\")\n.attr(\"y\", function(d,i){\nreturn i * 30 + 5;\n})\n.attr(\"x\", radius * 5)\n.text(function(d){\nreturn d;\n});\nUse ‘d’ in function for the data entry, and ‘i’ for index of the data entry."
  },
  {
    "objectID": "posts/2016-05-02-notes-for-learning-d3-js.html#create-scale-to-map-the-domain-of-data-to-the-range-on-the-canvas",
    "href": "posts/2016-05-02-notes-for-learning-d3-js.html#create-scale-to-map-the-domain-of-data-to-the-range-on-the-canvas",
    "title": "Study Notes for D3.js - 7 Basic Concepts to Grasp",
    "section": "5. Create scale to map the ‘domain’ of data to the ‘range’ on the canvas",
    "text": "5. Create scale to map the ‘domain’ of data to the ‘range’ on the canvas\nvar time_extent = d3.extent(data, function(d){\nreturn d['date'];\n});\n\nvar count_extent = d3.extent(data, function(d){\nreturn d['attendance'];\n});\n\nvar time_scale = d3.time.scale()\n                        .range([margin, width])\n                        .domain(time_extent);\n\nvar count_scale = d3.scale.linear()\n                          .range([height, margin])\n                          .domain(count_extent);\nHere ‘domain’ is the extent of the data range, while ‘range’ is the extent of the the plot on canvas.\nUse ‘.scale’ method with the appropriate scale. As an example, I used the ‘linear()’ map above. For time, do ‘d3.time.scale()’."
  },
  {
    "objectID": "posts/2016-05-02-notes-for-learning-d3-js.html#axis-are-special-functions-use-.call-on-elements-to-create-visualization-of-axis.",
    "href": "posts/2016-05-02-notes-for-learning-d3-js.html#axis-are-special-functions-use-.call-on-elements-to-create-visualization-of-axis.",
    "title": "Study Notes for D3.js - 7 Basic Concepts to Grasp",
    "section": "6. Axis are special functions, use ‘.call()’ on elements to create visualization of axis.",
    "text": "6. Axis are special functions, use ‘.call()’ on elements to create visualization of axis.\nvar time_axis = d3.svg.axis()\n                      .scale(time_scale)\n                      .ticks(d3.time.years, 2);\n\nsvg.append('g')\n.attr('class', 'x axis')\n.attr('transform', \"translate(0,\"+height+\")\")\n.call(time_axis);\nUse ‘d3.svg.axis()’ to create the axis function and set ‘.scale’ and ‘.ticks’."
  },
  {
    "objectID": "posts/2016-05-02-notes-for-learning-d3-js.html#finally-when-reading-data-from-csv-or-other-files-one-can-transform-the-data-before-passing-it-on-to-create-visualization.",
    "href": "posts/2016-05-02-notes-for-learning-d3-js.html#finally-when-reading-data-from-csv-or-other-files-one-can-transform-the-data-before-passing-it-on-to-create-visualization.",
    "title": "Study Notes for D3.js - 7 Basic Concepts to Grasp",
    "section": "7. Finally, when reading data from csv or other files, one can transform the data before passing it on to create visualization.",
    "text": "7. Finally, when reading data from csv or other files, one can transform the data before passing it on to create visualization.\nvar format = d3.time.format('%d-%m-%Y (%H:%M h)');\nd3.tsv(\"world_cup_geo.tsv\", function(d){\nd['date']=format.parse(d['date']);\nd['attendance']=+d['attendance'];\nreturn d;\n}, draw);\n‘d3.tsv()’ reads in the data, and pass it to the anonymous function, and then feeds the result to the user-defined ‘draw’ function for visualization. This is very convenient when one needs to convert some data format before moving on to the visualization step.\nHere I parsed the ‘date’ column and made them into a ‘Date’ type, and converted the ‘attendance’ column from string into a number using the unary operator ‘+’. The ‘draw’ is a function that draws the visualization of the dataset."
  },
  {
    "objectID": "ai_art-dd.html",
    "href": "ai_art-dd.html",
    "title": "Disco Diffusion",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\nTemple\n\n\n\n\n\n\n\n\n\nOct 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nCherry_blossom\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nForest\n\n\n\n\n\n\n\n\n\nAug 17, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nDusk\n\n\n\n\n\n\n\n\n\nAug 10, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nIslands\n\n\n\n\n\n\n\n\n\nAug 8, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPeter Pan\n\n\n\n\n\n\n\n\n\nAug 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nLagoon\n\n\n\n\n\n\n\n\n\nJul 18, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRoses\n\n\n\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nSpace Station\n\n\n\n\n\n\n\n\n\nJul 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nNight Fortress\n\n\n\n\n\n\n\n\n\nJun 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nJellyfish\n\n\n\n\n\n\n\n\n\nJun 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nSingles\n\n\n\n\n\n\n\n\n\nJun 5, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  }
]